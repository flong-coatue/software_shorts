---
file_id: 21433457
source_type: Sell-Side
url: https://mosaic.coatue.com/files/21433457
headline: 'The Growth Investor''s Guide to AI in 2026 & Beyond: A Candid Assessment
  of Cycle Hype vs. Reality'
file_name: Canaccord_AI_Outlook2026 - Hype vs Reality.pdf
broker: Canaccord Genuity
publish_time: '2025-10-08T00:00:00-04:00'
primary_tickers:
- GOOGL
- MSFT
- AMZN
- CF CN
- META
all_tickers:
- GOOGL
- MSFT
- AMZN
- CF CN
- META
categories:
- 2026 Outlook Reports
---

Canaccord Genuity

8 October 2025

Kingsley Crane | Analyst - 212.849.3954 kcrane@cgf.com Daniel Reagan | Associate - 617.788.1532 dreagan@cgf.com Emma Weise | Associate - 212.849.3932 eweise@cgf.com Susan Anderson, CFA | Analyst - 212.389.8009 SAnderson@cgf.com Richard Close | Analyst - 615.490.8501 rclose@cgf.com Caitlin Cronin, CFA | Analyst - 212.849.3925 CCronin@cgf.com George Gianarikas | Analyst - 929.697.1712 ggianarikas@cgf.com Michael Graham, CFA | Analyst - 212.849.3924 MGraham@cgf.com David Hynes Jr. | Analyst - 617.371.3882 DHynes@cgf.com Whitney Ijem | Analyst - 212.389.8094 wijem@cgf.com

Sumant Kulkarni | Analyst - 212.389.8037 SKulkarni@cgf.com Brian C. McNamara, CFA | Analyst - 212.849.3981 BMcnamara@cgf.com Kyle Mikson, CFA | Analyst - 212.849.3937 kmikson@cgf.com Austin Moeller | Analyst - 212.389.8198 AMoeller@cgf.com Luke Morison, CFA | Analyst - 617.371.3837 lmorison@cgf.com Edward Nash | Analyst - 212.389.8128 enash@cgf.com John Newman, Ph.D., CFA | Analyst - 212.389.8042 JNewman@cgf.com William J. Plovanic, CFA | Analyst - 847.864.1139 wplovanic@cgf.com Maria Ripps, CFA | Analyst - 212.849.3923 MRipps@cgf.com

Jason Tilchen, CFA | Analyst - 212.849.3928 JTilchen@cgf.com Joseph Vafi, CFA | Analyst - 415.229.0651 JVafi@cgf.com John Young | Analyst - 212.849.3920 jyoung@cgf.com Canaccord Genuity Corp. (Canada) Aravinda Galappatthige, CFA | Analyst - 1.416.869.7303 agalappatthige@cgf.com Doug Taylor, CFA | Analyst - 1.416.867.6101 dtaylor@cgf.com Robert Young, MBA | Analyst - 1.416.869.7341 ryoung@cgf.com

Enthusiasm for AI's potential to transform the world and create business value has captivated investors and defined broader market movements over the past three years. As chip production and datacenter buildouts have scaled and landmark 'circular' investments between AI leaders emerge, we find ourselves at a tipping point in the cycle. Will all this cumulative investment pay off, and for whom? Yes, fueling AI innovation matters, but being good stewards of capital does too. While questions around hyperscaler AI capex efficiency won't be answered quickly, it's becoming clearer that rapid, broad-based adoption

is creating a unique supply-demand relationship from prior cycles, which creates optimism that we won't see a prolonged AI winter, if at all. As we look into 2026, we expect improving cost curves to drive adoption in emerging markets while agentic workflows reshape how software is delivered in the enterprise. In this update to our Jan. 2024 whitepaper, we provide a comprehensive overview of CG's expertise across focus sectors-Technology, Healthcare, Sustainability, and Consumer-to help investors navigate what has proven to be the next great technology cycle.

1. We take a nuanced approach to tracking the cycle at what feels like a tipping point. Every investor conversation in AI seems to circle back to the same question: is this a bubble, and if so, where are we in the cycle? The debate is less about how much money is being spent (capex disclosures and GPU order books make that clear) and more about whether this spending is sustainable, coordinated, and likely to leave behind durable value. AI bears harbor healthy skepticism regarding the return on capex investment while scrutinizing "circular" investments in ecosystem leaders, but roadmap alignment and coordination creates valuable visibility.

2. Recurring investments in frontier model training paired with emerging inference-heavy workloads underpin powerful demand backdrop. Leading model builders continue to pay up to train frontier models even as diffusion techniques and open weight models create a rising tide dynamic benefiting all users. With inference workloads emerging as the next phase of growth as applications and agentic workflows embed better reasoning capabilities, the demand backdrop for AI compute remains constructive. 3. Model diversity is driving value up the stack toward orchestration and AInative apps. Longer term, commoditization of the model layer appears natural. As core capabilities converge, we expect that the point of differentiation will shift higher up the stack. Investors should expect the most durable value creation to occur in the middleware, orchestration, and AI-native application layers, with this battleground heating up in 2026.

4. Power generation remains a complex bottleneck. As datacenter demand surges toward gigawatt-scale footprints, the limiting factor for AI expansion has shifted from chip supply to energy supply. AI needs a lot of power, and there's limited excess electricity capacity to procure. While we work to rebuild the gas and nuclear supply chains, America likely needs renewables to bridge the gap. 5. AI use cases are proliferating and transforming sectors across Canaccord Genuity's research coverage. Data suggests AI adoption across technology, finance, and manufacturing surged over the past year, with early winners in code creation already aggressively monetizing. Between our public market sector commentary and our AI Private Watch List, our research analysts in the US and Canada have identified companies best positioned to take share and participate in this next phase of growth.

6. AI is a market-defining theme, but stay selective. Despite ongoing AI proliferation, "pure play" AI public equities are scarce. To cast a broad stroke, those that do exist have largely priced in success. We recommend a patient, selective approach as the ecosystem develops and price corrections inevitably occur. Canaccord Genuity is the global capital markets group of Canaccord Genuity Group Inc. (CF : TSX) The recommendations and opinions expressed in this research report accurately reflect the research analyst's personal, independent and objective views about any and all the companies and securities that are the subject of this report discussed herein.

| SECTORSPOTLIGHT                               | 3   |
|-----------------------------------------------|-----|
| HOWWE'RETRACKINGTHECYCLE                      | 7   |
| OURVIEW                                       |     |
| / Cost Curves                                 | 12  |
| / Public Cloud                                | 18  |
| / Model Performance                           | 24  |
| / Evolving Usage Patterns                     | 32  |
| / TheVerticalizationofAIand 'theDeathof SaaS' | 38  |
| / Hybrid pricing models embraceconsumption    | 40  |
| / Cybersecurity                               | 42  |
| / Quantum                                     | 45  |
| / Global race for AI leadership               | 47  |
| TECHNOLOGY                                    | 50  |
| / Internet                                    | 51  |
| / Software                                    | 53  |
| / FinTech                                     | 58  |
| / DigitalGaming&EdTech                        | 59  |
| / Digital Transformation Services             | 61  |
| / Aerospace&Defense                           | 62  |
| / CanadaSpotlight                             | 69  |
| HEALTHCARE                                    | 72  |
| / Biotechnology                               | 73  |
| / MedTech                                     | 74  |
| / Diagnostics &Life Science Tools             | 77  |
| / Digital &Tech-Enabled                       | 80  |
| SUSTAINABILITY                                | 82  |
| / Sustainability&AutonomousDriving            | 83  |
| CONSUMER                                      | 86  |
| / Home,Outdoor&Auto                           | 87  |
| / Beauty, Health &Wellness                    | 94  |
| AIPRIVATEWATCHLIST                            | 97  |

As we've alluded to, this is a highly collaborative report which provides a glimpse into Canaccord's thoughts on the impact of AI both now and in the future across the firm's coverage. While much of the initial revenue benefits of AI have been concentrated among hardware vendors and large cloud providers, AI's impact on competitive dynamics is widereaching. We've included some high -level comments from each of our analysts here as a precursor to the report in full. Detailed sector analysis begins in full on page 47.

/ Software Applications & Infrastructure . AI adoption continues to proliferate across industries, accelerating throughout this year, as companies integrate the technology into their contact centers, IT services, go-to-market teams and more in an effort to increase efficiency at the bottom line and accelerate growth at the top line. Although Gen AI is yet to meaningfully appear in financial results or demonstrate clear areas of monetization across the board for all industries, we are seeing early signs of pullthrough across developer platforms, data infrastructure, and observability/security vendors as AI workflows require end-to-end tooling. Our earliest observations on impacts from AI on the software space include disruptions to legacy SEO practices, possible evolution in pricing models from seat-based to more consumption- or outcome-based, increased efficiencies and more effective outcomes (within customer support, GTM functions, enterprise search), as well as heightened security risks from bad actors.

/ Internet. The AI race across the Tech sector continues to intensify, led by the Hyperscalers (Amazon, Google, Meta, and Microsoft), which are collectively projected to spend more than $350B in 2025 on CapEx, with the majority directed toward AIrelated initiatives such as scaling key infrastructure and integrating generative AI models into core products. Mega-cap tech as well as smaller companies are actively integrating AI across their platforms, fueling rapid innovation in personalization, automation, and overall platform efficiency. Nearly every company in our coverage is embracing AI as a core platform tool for driving (1) internal operational efficiencies and (2) new revenue opportunities, including the integration of AI into existing offerings, or the creation of entirely new AI-native products and services.

/ Fintech. While the FinTech sector is generally associated with disruption, at least for now, we see less impact either positively or negatively to the sector coming from the introduction of generative AI. Many automation tools already exist in FinTech across a variety of business models including those that are payments-, software- and lending-centric. Importantly, a material regulatory backdrop is part of the larger FinTech sector ecosystem; and we believe it will be a good while before regulators become comfortable with generative AI being used in most customer-centric activities. Still, we are seeing niche use cases for generative AI making their way into FinTech business models on an opportunistic basis. Clearly there are efficiency gains in adopting this technology on the back-end, but generative AI lends itself well as a tool when it comes to helping consumers with scenario analysis around topics such as down payment/monthly payments in mortgage and when it comes to driving internal efficiency gains.

/ Digital Assets. A key theme on the digital asset side is developing infrastructure to support the increasing demand for AI compute. At this point, nearly every public BTC miner has announced plans to strategically diversify their business into HPC/AI, which we believe makes sense given the strong demand backdrop and attractive economics. While the true ramp in demand for AI services is unclear, we do know that most hyperscalers and AI cloud providers are quite active in their data center procurement efforts.

/ Digital Gaming. The biggest area where AI is impacting online gambling companies is in personalizing the user experience, including which bet types and promotions are surfaced to each customer. Other important areas where companies are leveraging AI to drive efficiencies include customer support, responsible gambling, and backoffice operations. Within the video game industry, AI can help companies highlight the most popular and relevant content based on each user's preferences, and these tools also have the power to revolutionize game development. / EdTech. For the EdTech industry, AI tools serve as tutors and interactive study guides to help reinforce learning and training, though they may also be used to provide students with 'too much' help on assignments. Further, as technology transforms the responsibilities and skills needed for a variety of jobs across industries, we expect greater demand for training and reskilling through professional development platforms.

- / Digital Transformation Services. AI is reshaping digital transformation services, shifting the model from labor-intensive and people-driven to IP- and platform-led. This shift is changing commercial models as clients demand faster time-to-value and measurable outcomes, driving outcomes-based and gain-share pricing, more recurring managed services, and delivery models with data governance, security, and model observability baked in. AI's ability to compress software development cycle times, reduce costs, and improve quality by automating work processes has made it not just an efficiency tool, but a disruptive force that's redefining competitive dynamics, with providers that can productize, govern, and scale AI delivery positioned to capture a greater share of the market.

/ Aerospace & Defense. Within the Aerospace & Defense industry, AI adoption is expanding across verticals including UAS/C-UAS, Space Technology and Advanced Air Mobility. The most immediate impact is being felt both in the Drone and Space industries amidst greater US and allied government emphasis on global security. UAS/C-UAS technology utilizes AI to enable autonomous flight (even in GPS-denied environments), drone swarming capabilities, manned-unmanned aircraft teaming and

improved target identification, threat prioritization, and strike execution in combat scenarios. Predictive AI is already enhancing space domain awareness by improving orbital satellite traffic management and collision avoidance via autonomous tracking of satellites, debris and potentially hostile spacecraft. Further, AI is enhancing autonomous data processing and analytical capabilities, which are directly relevant to EO satellites processing and deriving insights from greater volumes of highresolution imagery and lunar science missions conducting autonomous entry, descent and landing operations on complex off-world terrain. NASA scientific research has been bolstered by AI-driven autonomous driving (robotic rovers like the future Lunar Terrain Vehicle), topographical analysis and hazard avoidance without input from a human operator. We additionally expect AI-driven automation to be implemented into the US air traffic control (ATC) network to reduce cognitive load on air traffic controllers in towers and enable safer travel throughout the National Airspace System. While not as immediate, we anticipate autonomous flight technologies to be applied to eVTOL passenger and

cargo aircraft. However, adoption remains dependent upon regulatory, safety and pilot union-related challenges.

/ Biotech. We view AI in biopharma as a potential tool to help automate and accelerate steps in the drug development process. So far, we have seen AI integrated into drug discovery models and processes for regulatory filing, and consider the potential for AI to help automate and accelerate multiple types of discovery results. However, AI has thus far only produced a few candidates in late-stage clinical trials, and none yet approved.

/ Medical Devices. AI could fully power the next wave of successful products or significantly accelerate the speed, efficiency and iterative development required for commercial success. In musculoskeletal and surgical care, AI could reshape how procedures are planned, performed and monitored, potentially improving outcomes. So far, AI has served as the backbone for developing diagnostic solutions, helped automate insulin delivery, and increased product efficiency and efficacy. As capabilities evolve and stakeholders grow more accustomed to utilizing these innovations, AI is likely to expand from a technology enabler to a core differentiator among companies in our coverage universe.

/ Diagnostics and Life Science Tools. AI is expanding across the space and creating exciting opportunities to better diagnose, treat and detect disease. Leveraging large volumes of data and laboratory results paired with a patient's clinical data has the potential to deliver new insights and more accurately and precisely address complex biological questions and individual patients' needs. So far, companies are using AI to help identify disease at earlier stages as well as increase speed and accuracy, predict responses to therapies, and improve analysis of multiomics data.

/ Digital & Tech-Enabled Health. Integrating AI technology into healthcare has already begun to improve efficiency within provider workflows, drive patient/member engagement and assist with patient diagnosis. In the past year, companies have begun to expand AI use in patient/member-facing capacities through nutrition bots and personalized health content, and more recently into clinical reference tools that assist providers in the provision of patient care. AI adoption from here is likely slower than other industries considering the greater risks and regulations, but continues to be a source of significant investment.

/ Sustainability & Autonomous Driving. AI has the most direct impact on vehicle autonomy among companies in our coverage universe. Companies like Aurora, Tesla and Mobileye are expanding autonomy's reach in the US and abroad. Within the ecosystem, sensor manufacturers such as Aeva and Arbe are additional beneficiaries while companies like Uber and Lyft may face disruptive threats depending on how they vs. competitors scale their platforms. Increasing demand for AI and autonomy will drive energy consumption and opportunity for energy and battery companies to meet those needs. We currently sit at the inflection point of autonomy, and with the help of companies specializing in batteries, energy and rare earth minerals, our roads could look very different in the coming years. Analyst: George Gianarikas

/ Health, Wellness and Lifestyle. The beauty, health, and wellness sector are continuing to benefit from AI-powered tools across product development, operations and customer service. These companies are utilizing various AI products and capabilities to offer personalized shopping experiences, improve their inventory management, or even speed up their product development capabilities. We have already seen AI help companies leverage decades of consumer data to better develop products and services that are personalized to specific customer health issues or needs at a faster pace.

/ Home, Outdoor and Auto. AI is most impacting the consumer in their search and purchase behavior, prompting companies to shift their approach to customer acquisition and retention when it comes to reviews and social engagement. So far, AI has already created efficiencies in processes and data analysis, allowing consumers to consider and consume more content than ever before. Our coverage names continue to integrate AI into sales outreach, back-end operations and customer service. Looking ahead, we believe AI will continue to shift power from brands to consumers as the latter gains unprecedented access to AI technologies and becomes savvier and more discerning, hastening both brand adoption and abandonment. With SharkNinja's business model based on 5-star reviews, we believe it is the company in our coverage most impacted by AI in the near term. Analyst: Brian McNamara

| OpenAIGigawattCommitments   | OpenAIGigawattCommitments   | OpenAIGigawattCommitments   | OpenAIGigawattCommitments                | OpenAIGigawattCommitments   |
|-----------------------------|-----------------------------|-----------------------------|------------------------------------------|-----------------------------|
| Date                        | Partner                     | GWCommitment                | Funding Details                          | Funding Amount($)           |
| May-25                      | Oracle                      | 4.5GW                       | 5-year contract                          | $40B                        |
| Sep-25                      | NVIDIA                      | 10GW                        | Invest progressively as eachGWisdeployed | $100B                       |
| Oct-25                      | AMD                         | 6GW                         | Warrant for160Mshares                    | ~$34B*                      |
| Total:                      |                             | 20.5GW                      |                                          | $174B                       |

Source note: * = approximate funding from taking 160M share warrants and multiplying by the current share price of AMD ($210 USD) and rounding.

Every investor conversation in AI seems to circle back to the same question: is this a bubble, and if so, where are we in the cycle? The debate is less about whether money is being spent (capex disclosures, GPU order books, and model funding rounds make that clear) and more about whether this spending is sustainable, coordinated, and likely to leave behind durable value. That framing matters for our process because the answer shapes how we underwrite the next leg of growth. If today's exuberance is only spe culative froth, then multiples may be inflated. If instead, this 'bubble' is a productive coordination device, then the overbuild may not be a red flag but a natural mile marker on the way to real adoption.

On the one hand, it makes perfect sense that the largest players in AI are coordinating their infrastructure investments. At this scale, the economics of compute become too large and too interconnected for any single company to manage in isolation. Shared planning around chip supply, power infrastructure, and data center buildouts improves visibility and enables faster infrastructure scaling as demand continues to outstrip supply. The fact that OpenAI is aligning its roadmap with the likes of NVIDIA, AMD, Oracle, and CoreWeave is a good thing, in our view, even if there is some healthy debate regarding the size and scope of these arrangements.

By the numbers, OpenAI has (in aggregate) entered purchasing agreements to acquire 20GWs worth of compute power over the next decade. The back of the envelope math du jour is that it could cost $1T to bring that capacity online using OpenAI's own estimate of $50B per 1GW. This is best viewed as a directional estimate rather than a literal one. It aggregates everything from GPU procurement to grid expansion into a single headline number and likely embeds conservative assumptions on pricing and capacity utilization. In practice, the cost per gigawatt will vary significantly depending on chip generation, efficiency improvements, and how much existing infrastructure can be reused. As utilization rates and hardware efficiency improve, the effective cost curve should flatten. While total capital requirements will be massive, the $1T figure likely overstates the actual spend.

Many of these headline agreements are less rigid than they appear. As eyepopping as some of these figures are, we view them more as long-term planning frameworks than hard purchase agreements with each including milestone-based triggers, equity incentives to partially offset cost, and potentially advantageous volume-discounted pricing given OpenAI's procurement scale. It's more than fair for investors to harbor skepticism about the scale of these agreements, but the real story is beyond the headline numbers.

While OpenAI's ability to rapidly scale to $12bn in ARR is nothing short of remarkable, it's clear that its revenue won't serve as the primary source of funds to build out all this infrastructure for some time. We believe two things can be true: 1) OpenAI is just beginning to scratch the surface of monetizing in the enterprise with consumer adoption continuing to lead the market, and its $125bn ARR target in FY29 is quite plausible, and 2) it's not too early for the firm to start building an internal cost discipline muscle as we inch closer to its positive FCF goal in FY29. To square the circle, the ever-growing web of financing and partner relationships between major AI players is worth scrutinizing but is to be expected given the outsized value of scale and the size of these agreements requires context beyond the headline numbers. This is a coordinated effort to accelerate a generational infrastructure transition that can look self-referential in the moment but ultimately lay the foundation for real, durable productivity gains as the cycle progresses.

Taking a step back, our job is to parse all of these signals throughout the space carefully, judging when capital is accelerating the future and when it risks getting ahead of itself. At a high level, here are a few major areas we're tracking as we continue to build our view on how AI is impacting markets:

Over the past five quarters, CapEx run-rates have surged to record levels, with the bulk earmarked for AI capacity. This matters not just because of the dollars spent but because of how those dollars cascade: chip vendors book out their advanced supply, model labs commit to multi-year cloud contracts, and data-center landlords rush to break ground on shells that can handle power-hungry workloads. In prior cycles, infrastructure investment tended to run one-way with telecoms building fiber and clouds building out general compute. What distinguishes this cycle is that the flywheel is circular. Nvidia invests in cloud providers like CoreWeave, guaranteeing to absorb unused GPU capacity, while the same clouds pre-commit to buy more hardware on multi-year terms. Model developers strike deals that resemble both customer contracts and financing arrangements. The capital loop keeps the flywheel spinning faster, and until one spoke weakens, it reinforces the sense that growth is self-sustaining.

Source: Canaccord Genuity Research, VisibleAlpha, FactSet

We' ve done our best to track tokens-per-dollar and the cost per unit of training or inference, even if disclosed imperfectly. The broad story is that costs continue to decline, but not nearly as quickly as demand is scaling. This imbalance is why the flywheel continues: as long as incremental performance gains unlock new demand, hyperscalers are willing to spend ahead of falling unit costs. We expect leading model providers will continue to pay up for leading-edge GPU capabilities even as costs for like-for-like functionality rapidly come down which continues to be a positive indicator for overall demand.

We think there's a real case for AI to exhibit characteristics of Jevon's Paradox , whereby efficiency gains lower the marginal cost of consumption in turn creating an increase in total consumption. Even as training and inference costs per token fall, overall compute demand is accelerating rather than plateauing. Lower costs expand the surface area of use cases whereas 18 months ago it would ruin a software business' unit economics for every customer-facing task and service to integrate AI.

|             | Release   | MMLU   | Input/Output   | Cost Improvement (Blended 80/20 I/O)   | Cumulative Reduction   |
|-------------|-----------|--------|----------------|----------------------------------------|------------------------|
| GPT-4       | Mar-2023  | 86.4%  | $30/$60        | -                                      |                        |
| GPT-4 Turbo | Sep-2023  | 86.5%  | $10/$30        | 3x                                     | 3x                     |
| GPT-4o      | May-2024  | 88.7%  | $5/$15         | 2x                                     | 5x                     |
| o4-mini     | Apr-2025  | 93.0%  | $1.10/$4.40    | 4x                                     | 20x                    |
| gpt-oss-20B | Aug-2025  | 90.0%  | $0.05/$0.20    | 22x                                    | 450x                   |

Source: Canaccord Genuity Research, Epoch AI

It's helpful to judge whether improvements in model quality actually translate into real demand. Benchmarks have become shorthand for capability, and reasoning tasks, coding benchmarks, and multi-modal performance all continue to improve. But the cycle only holds if better models show up as higher GPU utilization and incremental cloud AI revenue.

There was an extended period of overbuilding in the dot-com era, and when usage failed to keep pace, the industry endured a prolonged 'winter' as overcapacity sat idle until consumer internet applications finally caught up years later. With AI, the uptake curve looks steeper, in our view. Enterprises are already experimenting with copilots, agents, and embedded inference workloads, while consumer adoption of generative interfaces has ramped from zero to hundreds of millions of users in under two years. That doesn't eliminate the risk of overbuild, but it shortens the feedback loop: new capacity is being absorbed more quickly, turning what could have been a decade-long trough into something that more closely resembles a rapid scaling phase. Even if monetization lags capability, we believe each increment in model improvements and agentic utility creates just enough justification for the next round of infrastructure spend.

Leverage is a critical element in capital structures to enable scale, but it can also signal systemic risk if left unchecked. Today, leverage is concentrated in data-center REITs and specialized infrastructure financiers, while software and model labs remain largely equity-funded. We believe this mix is healthier than the dot-com period, when telecoms carried enormous debt burdens. But the sheer pace of AI buildout is pushing leverage higher, especially for firms financing shells and power upgrades. In some cases, layered on top are off-balance-sheet commitments like take-or-pay GPU contracts or prepayments for cloud access, which could behave like leverage when demand softens. All this is to say, there's room for leverage in the AI ecosystem to continue to move higher, particularly further up the stack.

Many model developers depend on a single GPU vendor, although this is beginning to change with Advanced Micro Devices (AMD) showing signs of reaching parity with Nvidia while the latter's software differentiation may not be as bullet -proof as originally thought. Many infrastructure providers depend on a handful of hyperscalers or one or two frontier labs. This degree of counterparty exposure can create fragility: if a single relationship shifts, capacity utilization and financing terms can change overnight. We have already seen examples in CoreWeave's disclosures, where a material portion of revenue is tied to one or two model customers, while a significant portion of its GPU fleet is tied to one vendor's roadmap. These are not inherent structural flaws but pose incremental risk if the nature of those relationships are to change.

Every gigawatt of new AI capacity requires permitting, interconnects, and long-term power purchase agreements. Delays here can slow the flywheel as surely as would a shortfall in model progress. Our Sustainability analyst George Gianarikas and his team have followed this quite closely, and from their vantage point, there are real energy capacity concerns looming that could prove to constrain actual AI usage even as demand appears to ramp. Figure 4: US Total Power for AI Data Centers (in GW) Source: Canaccord Genuity Research, Epoch AI AI workloads are straining the grid, with permitting delays, a gas turbine crunch, and nuclear still years away from adding meaningful capacity. Renewable deployment has slowed, water demands are climbing, and communities are already showing resistance to higher costs. The risk is less that spending halts outright, and more that the pace proves unsustainable, leaving pockets of overbuild and pressure on margins.

Source: Canaccord Genuity Research, Company reports -(01/25) DeepSeek releases chatbot and R1 model -(01/25) DeepSeek -R1 becomes most downloaded IOS app in US DeepSeek -R1 becomes most downloaded IOS app in US -(03/25) OpenAI raises $40B at $300B post money valuation

-(09/25) OpenAI, Oracle, and Softbank expand Stargate to 5 new data centers OpenAI, Oracle, and Softbank expand Stargate to 5 new data centers -(09/25) OpenAI and NVDA announce intent to deploy 10GW using NVDA systems

One of the most important early questions in the AI cycle was, 'how quickly (and by how much) can LLM costs come down?' In those early days, the focus was simply on the billions being spent on ever-increasing Nvidia H100 GPU clusters to train the next smartest model. The scaling law held up for a while (more data + more GPUs = smarter models) until model providers began to run out of new data and returns began to diminish. In January 2025, the conversation shifted when news broke about China's DeepSeek model only costing ~$5.5M to train (~2K H800s over ~2.8K hours) versus what had become a standard $100M+ and growing for each new model in the US. This moment raised a deeper question: were the hundreds of billions being poured into chips, DCs, models, and power truly necessary, and would those investments ever pay off?

That moment also reignited debate over Jevons Paradox, a concept Microsoft's Satya Nadella referenced directly: 'Jevons paradox is coming again!' The idea is simple: as AI becomes more efficient and accessible, usage explodes, turning compute into an addictive commodity. And indeed, while efficiency gains have accelerated adoption, the cost curve has grown increasingly noisy. The costs of many flagship models have gone up in absolute terms (like Opus 3.5 to Opus 4.1) while costs have come down across several new efficient models (like Gemini 2.5 Flash-Lite and Gemma 3). The divergence reflects both steady cost improvements and a massive expansion in global AI infrastructure with hundreds of billions of dollars in GPUs deployed over just a few years. With that hardware base in place, the focus has shifted from scale to reasoning: users now demand smarter, more accurate responses, and model developers are responding accordingly.

We saw this as an opportunity to synthesize the data and illustrate what the true cost curve looks like. The analysis begins with the AI infrastructure supply response, examines the forces bending that curve, and concludes with the most important piece of the equation: the return curve. We explore each in detail below.

While there is no definitive count of total AI chips in deployment, we estimate the installed base of Nvidia H100-equivalents (the largest portion of the AI stack compute mix) is ~5M, up from ~1M just a few years ago based on quarterly FLOP/s compute capacity provided by Epoch AI (see supplementary chart below). As the foundation of the AI cycle, GPU purchases remain the largest component of AI infrastructure CapEx, driving several years of supply constraints that have only recently begun to ease. GPUs now dominate hyperscaler budgets, with Nvidia capturing about 46% of aggregate hyperscaler CapEx in 2024, up sharply from roughly 8% before the GenAI boom.

At a higher level, this reflects a concept Jensen Huang often emphasizes: the global data center replacement cycle. The world is shifting from CPU-based generalpurpose computing to GPU-accelerated computing, triggering a fundamental transformation of global infrastructure. Nvidia estimates this transition could support roughly $1T in cumulative data center buildouts by 2030, a figure that aligns with our own back-of-the-envelope math. Several dynamics support this outlook. On the competitive front, access to leading GPUs at scale has become a strategic differentiator. Elon Musk's Colossus -1 cluster, for example, amassed about 200,000 GPUs in just 212 days, enabling the release of Grok 4, now among the highest-ranked large language models on benchmark leaderboards.

Another driver is what might be described as 'the more you buy, the more you make.' Public cloud providers face limits on both square footage and power within existing data centers, along with long lead times for expansion. By securing the latest GPUs, they are able to pack more compute capacity into each square foot and unlock larger token-based revenue streams. The bottom line here is that new generation GPUs are seeing ~20-30x better energy efficiency with improving cost-performance, which is enabling effective capacity growth even before raw unit counts increase. In combination with a continued supplydemand imbalance, we see continued runway for a sustained upgrade cycle. Figure 6: Total NVIDIA H100-Equivalent Chips Installed Source: Canaccord Genuity Research, Epoch AI

Power has become the gating constraint on AI capacity and is increasingly viewed as one of the sector's biggest challenges. Industry estimates place U.S. AI power demand at roughly 5 GW today, rising by an order of magnitude to more than 50 GW by 2030, with most of the growth driven by GPUs. According to 451 Research, GPU capacity could account for 82% of newly added datacenter power capacity by 2030 (see chart below). This surge is being driven by both training and inference demand growth (which we talk about in the next section). Frontier training runs now draw anywhere from 4-16 GW of power each, implying compute scaling roughly 10,000x greater than what GPT4 required.

This dynamic has direct implications for the AI infrastructure investment cycle. If gigawatts, not GPUs, are the governor, hyperscaler spending may remain elevated during a holding period while power capacity comes online. Several major players have signed long-term power purchase agreements (PPAs) spanning 10 -25 years, often with preferred pricing that should help profitability over time. However, the waiting period does little for near-term CapEx returns. In many cases, grid lead times are now setting the cadence for AI revenue ramps. We've heard from multiple hyperscalers that GPUs are already installed but sitting idle, waiting for power to go live. The result is slower AI revenue recognition despite chip availability.

Global GPU shipments' impact on data center capacity in MW _ 2023-2030 Source: Canaccord Genuity Research, S&P Global

A key paradox has emerged in the current AI cycle: the decline in inference costs has outpaced Moore's Law , with the marginal cost of intelligence falling roughly 280x in under 24 months, while training costs have risen about 4.4x per year since 2010. This has created a bifurcated dynamic. On one hand, lower inference costs are accelerating adoption and enabling a surge in AI application development. On the other, escalating training costs are concentrating the ability to fund next-generation state-of-the-art models among only a few players, such as OpenAI, Anthropic, and xAI.

Training Costs for SOTA Models is Skyrocketing Costs to Achieve Valuable Results is Plummetirg Source: Canaccord Genuity Research, Company Reports, Epoch AI On the inference side, the cost curve keeps bending down through a combination of GPU efficiency gains, model efficiency breakthroughs, and infrastructure optimizations. Getting a bit more granular, the evolution from NVIDIA Hopper to Blackwell has brought 25-30x better system level inference energy efficiency Looking further back, a single Blackwell GPU uses about 150,000x less energy per token than the 2014 Kepler generation. Algorithmic advances have been equally important, with techniques such as mixed-precision matrix computation and model distillation dramatically improving throughput and cost efficiency.

OpenAI's token pricing provides a clear example of this trend. Since 2023, pricing has fallen from GPT-4 at $30/$60 (I/O per 1M tokens) to GPT-4 Turbo at $10/$30, to GPT4o at $5/$15, to o4-mini at $1.10/$4.40, and finally to the open-weight gpt-oss-20B at $0.05/$0.20. Infrastructure optimization has also played a role. Microsoft recently noted that software enhancements enabled a 90% increase in tokens processed per GPU year over year.

|             | Release   | MMLU   | Input/Output   | Cost Improvement (Blended 80/20 I/O)   | Cumulative Reduction        |
|-------------|-----------|--------|----------------|----------------------------------------|-----------------------------|
| GPT-4       | Mar-2023  | 86.4%  | $30/$60        | -                                      | Token Costs                 |
| GPT-4 Turbo | Sep-2023  | 86.5%  | $10/$30        | 3x                                     | 3x                          |
| GPT-4o      | May-2024  | 88.7%  | $5/$15         | 2x                                     | 5x See Dramatic Improvement |
| o4-mini     | Apr-2025  | 93.0%  | $1.10/$4.40    | 4x                                     | 20x in <3yrs                |
| gpt-oss-20B | Aug-2025  | 90.0%  | $0.05/$0.20    | 22x                                    | 450x                        |

Source: Canaccord Genuity Research, Epoch AI The story on the training side is quite different. Compute requirements for training frontier models have grown roughly 4 -5x per year since 2010, as meaningful capability gains have depended on scaling model size and total floating-point operations. This r eflects the widely discussed ' AI Scaling Law ,' describing the predictable relationship between a model's performance and its parameters, dataset size, and compute power. Research from Epoch AI indicates that leading labs remain in full scaling mode (OpenAI at approximately 5.3x per year, Google DeepMind at 4.9x, and Meta at 7.1x) with the broader trend still pointing to 4 -5x annual training compute growth from here.

|                | Release   | Chip Quantity (Est.)   |   Training Compute (FLOPs Est.) | Training Cost (Est.)   | Cumulative Increase   |                          |
|----------------|-----------|------------------------|---------------------------------|------------------------|-----------------------|--------------------------|
| GPT-3          | May-2020  | 10,000                 |                        3.14e+23 | $2,200,000             |                       |                          |
| GPT-4          | Mar-2023  | 25,000                 |                        2.1e+25  | $40,700,000            | 19x                   | SOTA Model Training Sees |
| Llama 3.1-405B | Jul-2024  | 16,384                 |                        3.8e+25  | $51,000,000            | 23x                   | Dramatic Increase over   |
| Gemini 2.5 Pro | Jun-2025  | 100,000                |                        5.6e+25  | $200,000,000           | 91x                   | 5-years                  |
| Grok 4         | Jul-2025  | 200,000                |                        1e+28    | $480,400,000           | 218x                  |                          |

As discussed in our prior AI whitepaper, the first wave of monetization concentrated at the silicon layer and has since broadened into cloud AI services and frontier model revenue. Nvidia's data center business is on pace to add roughly $140B in total net -new revenue between the end of 2023 and 2025E. Its revenue continues to grow in dollar terms as Blackwell ramps, though year-over-year growth rates are moderating as the base expands. At the services layer, hyperscalers are now realizing meaningful AI contribution. Microsoft reported that its Azure AI business surpassed a $13B run rate earlier this year and contributed 16 points to growth in the March 2025 quarter. Amazon noted that AWS AI is a 'multi -billion dollar business' growing triple digits year over year. Google reported that its AI infrastructure and GenAI solutions have already generated 'billions in revenues' year -to-date in its June 2025 quarter. Each hyperscaler continues to highlight demand outpacing available supply, confirming that consumption is real rather than just committed.

At the model layer, revenue has become increasingly material as well. OpenAI generated about $4.3B in revenue in 1H25 and is expected to reach roughly $13B for the full year, with enterprise and API usage making up a growing share of the mix. AI-related revenue disclosures have generally been more limited or piecemeal in the Apps layer, which tells us the AI revenue curve is still phasing in. However, signals at some of the largest players have been turning green: (a) Salesforce saw Agentforce ARR surpass $100M ARR in FQ1 with the combination of Data Cloud and AI ARR reaching $1.2B in FQ2 (+120% y-o-y); (b) ServiceNow issued a $1B AI revenue target by the end of 2026, with Now Assist ACV already >$250M with consumption growing 50% month-over-month; and (c) Workday noted that overall AI revenue has surpassed >$450M (+50% y-o-y) and is driving ~1.5% ARR growth to the overall business at its Sept'25 investor day.

Our key takeaway is that clear signs of monetization are emerging across the stack. The wave of AI revenue that began with chips is now flowing through services and model layers and showing early but encouraging traction across infrastructure and applications. Looking out to 2030, we believe the slope of the return curve will depend less on raw model breakthroughs and more on the economics of delivery and the scaling of agentic workflow architectures that drive measurable business outcomes. If those trajectories hold, the massive CapEx outlays of the early years should be justified by meaningful revenue realization in the later years.

|                             | Revenue                     | Metric / Area                                 | Date          | Source              |
|-----------------------------|-----------------------------|-----------------------------------------------|---------------|---------------------|
| Silicon Layer               |                             |                                               |               |                     |
| Nvidia                      | ~$185B                      | Datacenter Revenue                            | Calendar2025E | FactSet Estimates   |
| AI Services Layer (Compute) | AI Services Layer (Compute) |                                               |               |                     |
| Microsoft                   | >$13B                       | Run-Rate / Azure AI RevsYTD / GCPAI&Solutions | Jan'25        | Q2/F25Earnings Call |
| Google                      | "Billions"                  |                                               | Jun'25        | Q2/25Earnings Call  |
| Amazon                      | "Multi-billions"            | Run-Rate/AWSAI                                | Jun'25        | Q2/25Earnings Call  |
| Model Layer                 |                             |                                               |               |                     |
| OpenAI                      | >$12B                       | ARR                                           | July '25      | TheInformation      |
| Anthropic                   | >$5BRunRate                 | Run-Rate                                      | Aug'25        | Anthropic           |
| AppsLayer                   |                             |                                               |               |                     |
| Salesforce                  | $1.2B                       | ARR/DataCloudandAIARR                         | Aug'25        | Q2/F26Earnings Call |
| ServiceNow                  | $1B                         | ACV/AIbiz end of2026                          | 2026          | May'25 InvestorDay  |
| Workday                     | >$450M                      | Revenue/ AI Contribution                      | Sept'25       | Sept'25 InvestorDay |
| Other AI Layers             |                             |                                               |               |                     |
| Databricks                  | >$1B                        | Run-Rate / AI Business                        | Sept'25       | Databricks          |
| Anysphere (Cursor)          | >$500M                      | ARR                                           | Jun'25        | Cursor              |
| Mistral AI                  | ~$330M                      | ACV                                           | Sept'25       | Mistral             |
| ElevenLabs                  | >$200M                      | ARR                                           | Sept'25       | ElevanLabs          |
| Perplexity                  | >$150M                      | ARR                                           | Mar'25        | Perplexity          |
| Cohere                      | >$100M                      | ARR                                           | May'25        | Reuters             |
| Glean                       | >$100M                      | ARR                                           | Feb'25        | Glean               |
| Lovable                     | >$100M                      | ARR                                           | Jul'25        | Lovable             |

We performed a focused deep dive on Microsoft's AI economics to gain perspective on the key question: "Will revenue eventually justify massive CapEx AI investments?" Microsoft is one of the few hyperscalers with sufficient disclosure to make this analysis possible, and our review primarily centers on Azure AI infrastructure. Any AI monetization from M365 Copilot price increases or other application-layer products should therefore be viewed as additive. In terms of assumptions, we've gathered the following:  Azure AI Contribution: Between calendar quarter Q2-2023 and Q1-2025, management disclosed that AI contribution to Azure growth was 1%, 3%, 6%, 7%, 8%, 12%, 13%, and 16%, respectively. Note that we make a conservative assumption for Q2-2025 of 17%.  CapEx Mix for AI Infrastructure: Beginning in calendar quarter Q2-2024 (FQ42024), management noted that "Cloud and AI-related spend represents nearly all of our total capital expenditures." The messaging stayed consistent through the

most recent quarter. As such, we set the CapEx mix for AI infrastructure at 25% in Q2-2023 and ramping up to 85% by Q2-2024 (earmarked mgmt. messaging), then to 90% for each quarter through Q2-2025. To assess how effectively this AI CapEx has translated into revenue, we compared trailing-twelve-month (TTM) AI-related CapEx with subsequent TTM Azure AI revenue. Based on management's mix disclosures and Azure metrics, we estimate that roughly $37B of AI CapEx deployed from calendar Q3-2023 to Q2-2024 generated about $11B of AI revenue in the following 12 months (Q3-2024 to Q22025). This implies an annual AI CapEx yield of approximately 30% and a payback period of roughly 3.5 years if trends persist.

Looking ahead, Microsoft expects overall CapEx growth to moderate in its current fiscal year. Coupled with roughly 90% higher token throughput per GPU and demand still exceeding available compute capacity, we see a conservative scenario in which AI revenue continues to justify investment at a similar yield and payback profile.

AI-Revenue from Recent 4-Qtrs versus AI-CapEx from Prior 4-Qtrs Source: Canaccord Genuity estimates, Company reports Let's begin by level-setting where we are by diving a bit deeper into our CapEx conversation earlier. Aggregate CapEx among the Big Three hyperscalers has risen from $107B in 2021 (before the ChatGPT breakthrough and onset of the AI cycle) to an expected more than $300B in 2025, growing roughly 50%. While these headline figures often drive debate, the more relevant metric, in our view, is the CapEx-to-Revenue ratio, as it reflects true capital intensity and helps indicate where we are in this AI cycle.

From 2015 to 2023, this ratio averaged around 10%, before jumping above 20% in 2024. The increase has been funded largely by higher operating cash flow allocations and cash reserves, though it has naturally pressured free cash flow margins and discounted cash flow models. Most industry analysts view CapEx-to-Revenue levels above 25% as unsustainable. Consensus projections show the ratio peaking at roughly 25% in 2026 before trending lower through 2030 as year-over-year CapEx growth moderates. Our expectations align broadly with that view. We see total CapEx remaining elevated on a dollar basis through 2026 -2027, then easing into the back half of the decade as more power capacity comes online and the foundation of the AI infrastructure buildout solidifies.

Source: Canaccord Genuity Research, VisibleAlpha, FactSet This dynamic suggests two things. First, it places a notional ceiling on CapEx trajectory under baseline assumptions. Second, and more importantly, it raises the question of whether public clouds can continue building AI infrastructure at a pace that matches the compute demand implied by training, inference, and adoption trends. If the CapEx ratio is effectively capped at 25%, the pace of investment becomes tied to revenue growth. Bain recently analyzed this relationship and estimated that meeting projected compute demand by 2030 would require roughly $500B in annual data center spending, which in turn would need about $2T in annual revenue to sustain a 25% CapEx-to-Revenue ratio. That would imply nearly $800B in additional revenue relative to today.

While informative, we view these projections as more theoretical than practical. They assume unconstrained scaling and model the hypothetical compute needed if current scaling laws and demand trajectories were simply extrapolated forward. There's a strong case that power availability and interconnect capacity will serve as the limiting factors rather than boardroom willingness to spend. At present, training continues to represent the majority of compute demand. Power requirements for frontier model training have roughly doubled each year, even as hardware efficiency improves, keeping the training curve steep. Meanwhile, inference costs continue to decline exponentially and now represent only a fraction of training costs, while we see pathway for the proliferation of inference-based AI applications to create a Jevons-like expansion of AI compute consumption.

We think today's SOTA models are already 'good enough' for many enterprise tasks and that the choke points are data readiness and the pilot-to-production chasm, not another order of magnitude of parameters. MIT came out with a rather striking report showin g that ~95% of firms aren't seeing the returns they expected yet and has many stuck in pilot phases. In our view, frictions preventing adoption at scale can ' t be solved simply by more FLOPs. We think the next major unlock for AI growth will be come from a focus on things like AI-data readiness, which Gartner suggests is a key reason AI deployments fail to meet objectives, along with governance, and improving agentic workflow reliability. We expect inference volumes will follow from here.

Our bottom line view is that training remains a meaningful driver of AI compute demand through 2030 and will contribute to sustaining the CapEx flywheel even as inference workloads become predominant among a much broader set of customers. However, the key constraints over the next several years will be power availability and productization, not model IQ. The race toward AGI and perfectly accurate models will persist, but the true pace of CapEx will hinge on power readiness and enterprise workflow scaling rather than pure frontier model ambition.

Hyperscalers are being forced to walk a fine line between overbuilding and underbuilding AI infrastructure, a dynamic that should help keep CapEx in check and lends credibility to management commentary about aligning capacity with demand signals. The dilemma is clear: betting on durable demand trends requires heavy upfront AI infrastructure investment to secure future revenue and maintain leadership. But if demand proves materially softer than expected, hyperscalers risk being caught in an 'overbuild' scena rio, with contracted power and underutilized assets weighing on returns. We view this as an important dynamic within the AI cycle because these allocation choices directly shape pricing, margins, and ecosystem momentum. Balancing capacity against supply chain constraints (particularly power availability) will remain a critical inflection factor to watch. Ultimately, we believe this push-and-pull should help keep CapEx discipline aligned with realized revenue growth.

ORCL shares surged more than 40% following FQ1 results (vs. -1.56% IGV Index), driven primarily by the signing of four multi-billion-dollar contracts with three major customers that pushed remaining performance obligations (RPO) to $455B, up 359% year over year and $317B sequentially. The majority of this increase is attributed to OpenAI, which reportedly signed a contract to purchase roughly $300B in computing power over the next five years. The other agreements are believed to involve xAI and Meta. In conjunction with these announcements, management raised its FY26 outlook, increasing Cloud Infrastructure revenue guidance by $1B and projecting RPO above $500B, up from previously implied levels near $275B, citing multi-year contracts that will carry it beyond that mark. CapEx guidance was also raised to $35B, up from $25B, reflecting accelerated infrastructure commitments (see below).

Source: Canaccord Genuity Research, Company reports

Another major takeaway from the announcement was management's long-range target for Oracle Cloud Infrastructure (OCI) revenue to reach $144B by FY30, driven largely by accelerating AI compute demand. Within the public cloud space, we think this suggests ORCL will be joining what was the Big-3 (AWS, Azure, GCP) to form a Big-4 within the next few years on a revenue basis, with Google making a serious push as well. Historically, Oracle has been well behind in the public cloud space. Figure 16: Big-3 Cloud becoming B-4 with Oracle Source: Canaccord Genuity Research, Company Reports, FactSet consensus forecasts

Source: Canaccord Genuity Research, Company Reports, FactSet consensus forecasts Jensen Huang has projected that data center CapEx could reach $1T annually by the end of the decade, and we see several vectors that make this plausible. Scaling enterprise deployments, including 100x compute agentic workflows, are driving significant inference demand. Next-generation model architectures and tooling improvements are making models more intelligent and capable, with autonomous, always-on predictive features that require higher inference token throughput. Stateof-the-art training costs continue to grow exponentially, while a growing number of smaller, purpose-built models trained for specific use cases are contributing to overall compute growth. We are also entering the phase of the cycle where AI-native applications are becoming more prominent, further reinforcing infrastructure demand. Collectively, these dynamics point to continued upward pressure on AIrelated CapEx.

That said, much of the physical infrastructure buildout may be nearing completion, aside from longer-lead items such as power generation and transmission. As business deployments scale and model efficiency improves, performance gains across the GPU, model, and software layers should help offset some of the raw compute intensity, allowing for a more balanced CapEx profile over time.

We also expect hosting of compute infrastructure to become increasingly diversified. OpenAI's $300B compute contract with Oracle this year marks a notable shift away from Microsoft. CoreWeave has emerged as a key independent provider, generating roughly $2B in revenue in 2024 and projected to grow at over 100% CAGR through 2027 to around $18B. Another major development is vertical integration among the largest consumers of public cloud compute. OpenAI recently announced plans to deploy at least 10 GW of AI datacenters (roughly 4-5M GPUs, beginning in 2H26) as part of a $100B investment with Nvidia. Similarly, xAI spent an estimated $3-4B building its Colossus 1 cluster of around 200,000 GPUs in 212 days, with a Colossus 2 supercluster planned to house roughly 1M GPUs. Our bottom-line view as we look out to 2030 is that CapEx levels among the core hyperscalers (MSFT, GOOG, AMZN) will begin to normalize. While absolute spending will remain elevated, growth rates should continue to moderate.

New LLMs are seemingly released every month, and it can be hard to track where we are now, and how far we have come, and more importantly, where we're headed. When we look at the key benchmarks for models and the progress they have made over time, there are a few key themes we want to highlight. First, while model intelligence scores on key benchmarks have markedly improved over the past two years, we see considerable runway for improvement as the goalposts continue to move and we move towards creating valu e through AI 'middleware' and orchestration layers.

While some thought leaders in the space have been vocal about a longer-term goal towards AGI, we begin by grounding this discussion in measuring leading models on key benchmarks. A commonly used benchmark for a model's intelligence is Humanities Last Exam, which spans questions across math, sciences, and humanities with the goal of testing the breadth and depth of advanced intelligence of models. With the recent rollout of GPT-5 from OpenAI, we continue to see marked improvements in scores on this benchmark, though results remain well short of perfection.

Source: Canaccord Genuity Research, Artificial Analysis Despite the gap to perfect accuracy, the pace of progress is striking when compared with the earliest versions of these models. Examining benchmark scores against release dates highlights that most launches still fall outside the 'attractive region' of both high intelligence scores and early release. This underscores why frontier models remain central to advancing the market; they have consistently set the upper bound for what is possible, even if incremental gains have come at a high cost. The most substantial leaps have coincided with a surge in funding and CapEx investment over the past 12 -18 months, a pattern that reinforces why companies will continue to prioritize investment in building frontier systems. Simply put, the race at the frontier not only drives model performance forward but also anchors the broader ecosystem of applied AI.

Source: Artificial Analysis Looking more broadly at the trajectory of frontier language model intelligence over time, the story becomes even clearer. The first wave of frontier models released in 2022 -2023 were perceived as nearly magical in their capabilities. Yet, only a few years later, they now appear rudimentary compared to today's leaders.

Source: Artificial Analysis These comparisons underscore how early advances, while gradual, laid the groundwork for today's rapid gains. The foundation built during those years has enabled the more significant jumps we are now seeing in model intelligence and suggests further headroom for improvement as both research intensity and infrastructure scale continue to expand.

In the early stages of this AI-driven compute cycle, model training and fine-tuning served as the primary driver of compute demand. As models improve and computational techniques evolve, there is a growing case to be made that inference will take on a more meaningful role in overall compute demand. To compare the two at a high level, model training is using compute resources to better understand the Release Date dataset prior to interacting with a user's request, whereas inference becomes more compute-hungry when it begins to layer in more chains of thinking into understanding a user's request in the context of the trained dataset.

Some leading researchers in the space believe that we're nearing a 'wall' in terms of the size of datasets available to feed into models as well as even seeing some diminishing returns on the effectiveness of a GPU cluster potentially scaling beyond 200K GPUs (the largest built today). Less than a year ago, former OpenAI leader Ilya Sutskever declared that 'pre -training as we know it will end' in a presentation at an AI developer conference. The jury is very much still out, but regardless of the potential scaling limitations that may emerge with model training over the next few years, new opportunities for inference to drive improved outcomes inform our optimistic outlook on the future for AI-powered applications over the next decade. Over the past year, we' ve seen a marked mix-shift away towards inference compute away from model training and fine-tuning. Figure 21: Compute spend across cohort and uses

Source: Menlo Ventures We are viewing the inference compute opportunity not as a zero-sum game vs. model pre-training but as another driver of overall compute demand. There are plenty of skeptics who believe that model improvements are beginning to taper off. If models like GPT-5 are indeed much better at complex problem solving, as some of the benchmarks suggest, then our view is that there will be demand for those services, even if they're resource -hungry. Effective but resource-hungry models will extend the runway for AI demand, and the data corroborates this. If you strip away all the headlines and hype and look at the pace of improvements at the model layer, we find it difficult to bet against the pace of AI advancements at what we view to be still early innings of the cycle. And as investment into models and training new models has grown considerably, the benefit becomes more widespread. Market dynamics tell a story of 'a rising tide lifts all boats.'

Early models quickly became proficient at regurgitating factual information, but when it came to deep thinking and analysis, they were clearly well behind what many expected. As models have progressed over the past year, we've seen meaningful strides in higher reasoning capabilities.

Source: Canaccord Genuity Research, Artificial Analysis Artificial Analysis's Intelligence Index results indicate that there are clear leaders (OpenAI, Gemini, Grok) but also a range of models from a variety of providers still relatively competitive with the top players. Despite Claude 4.1 Opus trailing the leaders in this index, Claude excels in some component benchmarks and enterprise usage data suggests that Claude remains competitive and appears to have made inroads within the past year. While some of these higher reasoning benchmarks are included in the Artificial Analysis Intelligence Index, by looking at some of the bluechip benchmarks by themselves, we can examine the reasoning skills of models more directly.

Source: Canaccord Genuity Research, Artificial Analysis As seen above, Claude, OpenAI's, and Grok models lead the pack, but not by staggering margins. The MMLU benchmark stands for Massive Multitask Language Understanding. It's one of the most widely cited benchmarks for evaluating large language models. The test consists of 15,908 multiple-choice questions spanning 57 subjects across the humanities, STEM, social sciences, law, medicine, and more. The questions are designed to resemble academic exam problems, ranging from high school level all the way up to professional certifications. The breadth of topics combined with the difficulty of the subject matter makes MMLU an appropriate frontier model benchmark. With 20/23 top models scoring >80% it serves as a strong case for the improving reasoning skills of models across the board, with early models like GPT-3 scoring ~43% not all that long ago.

Additional benchmarks lead to similar conclusions. Looking at the GPQA Diamond results (seen below), six players performed in the high 70's or above, with many models only marginally behind. GPQA stands for Graduate-Level Google-Proof Q&A. It was introduced in 2023 as a way to push models beyond MMLU-style factual recall and into genuine reasoning and problem-solving by incorporating questions that aren't able to be gamed by memorization. Within GPQA, GPQA Diamond is the most difficult subset. Early LLMs like GPT-3 often scored below 30% accuracy. This further supports the argument for the widespread benefit of increased investment.

Source: Canaccord Genuity Research, Artificial Analysis As models advance, so too do the benchmarks designed to test them. The emphasis has shifted from narrow task completion to understanding how far these systems can be stretched in reasoning, synthesis, and discipline-specific depth. Newer benchmarks like BigCodeBench demonstrate this trend, demanding not just memorization or pattern matching but genuine problem-solving across complex coding scenarios. Early results make clear that LLMs remain far from mastering this challenge, underscoring both the limitatio ns of today's models and the new frontier that still lies ahead.

Source: Canaccord Genuity Research, Artificial Analysis As we see it, a central theme emerging across the ecosystem is that model diversity is not going away but is only accelerating. Frontier labs may command attention with each new release, but the broader reality is a competitive and heterogeneous landscape where multiple architectures, training paradigms, and deployment models coexist. These models increasingly learn from one another, with open source serving as a powerful resource that accelerates diffusion of best practices and enables faster iteration acr oss the stack. We've already seen this dynamic play out in fine -tuning methods, data-efficient training, and evaluation frameworks, where communitydriven innovation rapidly seeps into commercial deployments.

An important clarification is that models are not monoliths. Techniques such as mixture-of-experts illustrate how specialization can be designed into a single system, enabling sub-components to focus on narrow tasks before surfacing a more consolidated, accurate response. In some sense, the competitive dynamic we see between model providers is mirrored within the architecture of individual models: multiple perspectives, routed and distilled into a more useful answer. Over time, this points toward commoditization of the model layer itself. As core capabilities converge, we expect that the point of differentiation will shift higher in the stack. Investors should expect the most durable value creation to occur not at the base model layer, but in the middleware, orchestration, and AI-native application tiers that govern how models are selected, combined, and operationalized in real workflows. This transition is already underway, with early signs of middleware playing a coordinating role between diverse model providers and the applications they power.

That is where the next wave of infrastructure investment will take shape: at the connective tissue that enables diversity at the model layer to be an asset rather than a liability. The story of AI to date has been framed largely as a model race. Bigger, better, and cheaper models continue to dominate the headlines, with benchmark leaderboards serving as the scoreboard. But beneath this contest, a quieter shift is underway. In enterprise settings, AI is rarely delivered through a single model. Instead, workflows are beginning to resemble systems of models, each optimized for a role and stitched together by a connective layer. This 'meta -layer' appears to be emerging as the real control point in the stack, as a form of operating system for enterprise AI.

Enterprises that adopt AI quickly find themselves orchestrating multiple components. Consider a typical customer support automation flow: a retrieval model surfaces relevant knowledge base documents, a reasoning model synthesizes an answer, a classification model determines whether escalation is needed, and a guardrail model ensures the response is free of hallucinations or PII. Financial services firms add compliance filters, while cybersecurity platforms run anomaly-detection models in parallel. The architecture is not one model at the center, but a sequence of decisions and checkpoints across multiple models. This is where the idea of AI middleware enters the picture. A growing set of frameworks and protocols are designed to help enterprises manage multi-model systems without bespoke integration. Arguably the most prominent is Anthropic 's Model Context Protocol (MCP), which is an early attempt to standardize how models, tools, and agents interoperate, passing context and instructions between them.

Google's Agent2Agent (A2A) Protocol pairs nicely with MCP by enabling agents to collaborate directly, passing tasks and contexts between them. The combination of the two helps to shift the architecture from linear pipelines to dynamic networks, where agent s negotiate, delegate, and verify one another's outputs. For enterprises, it highlights once again that value will not reside in any single model, but in the connective tissue that governs how agents interact which further reinforces the middleware opportunity.

Source: Canaccord Genuity Research, Rakesh Gohel

In our view, if orchestration becomes central to how enterprises use AI, the economics of the stack start to shift. By stitching together multiple models, middleware reduces dependence on any single vendor and makes it easier for enterprises to swap in alternatives. That, in turn, weakens the lock-in power of foundation model providers while strengthening the position of the orchestration layer. Over time, the orchestration logic itself (the rules governing which models are called, how results are verified, and how context is passed along) becomes deeply embedded in workflows. Changing a model may be straightforward, but replacing the orchestration layer would disrupt the entire system.

This dynamic also changes how performance is judged. Rather than focusing on which model scores highest on a benchmark, enterprises will increasingly care about the reliability, accuracy, and compliance of the system as a whole. What matters is not whether one model excels at math or coding, but whether the combined system produces answers that are consistent, safe, and auditable. And because middleware lowers the cost of trying new models or adding new tasks, it tends to drive more consumption overall. Instead of consolidating spend, enterprises often expand it, deploying AI in more functions and at greater scale once orchestration is in place. We've seen these shifts play out in earlier market cycles. We've yet to see definitive winners in this middleware layer emerge, but we believe it will define competition over the next few years.

Information & Search Substitution Entertainment & Lifestyle Productivity & Personal Assistance Consumer Services Motivations: Save time, convenience, cost reduction, andpersonalization Key

App Creation & Refinement Agentic App Development Expanding Model Accessibility Key Motivations: Enable ecosystems, capture mkt share; monetize Source: Canaccord Genuity Research

AI is out of the lab and into the hands of global users. Over the past two years, AI usage has proliferated in various forms with wide-ranging implications, whether it be a generative assistant embedded in consumer applications, a catalyst for businesses to rethink their technology stacks, or a lifeline for small businesses operating with lean resources. We're even seeing power users or 'prosumers' adopt AI in their personal lives to amplify productivity in similar fashion to SMBs while institutions leverage AI at broad scale for use cases like climate projections, economic forecasting, and tax fraud detection.

Low-Cost Scaling Faster Content Production Amplify Reach & Reduce Prep Work Motivations: Amplification of limited resources Key

Automation & Cost Reduction Decision Support & Analytics Product & Service Enhancement Innovation & Differentiation Motivations: Efficiency, scalability, innovation; andcompetitive advantage Key

Tax Fraud Detection Climate Projections Economic Forecasting Policy Simulations Motivations: Efficiency, better governance, public benefit, and security Key While government estimates derived from Census Bureau survey results may understate actual AI usage by asking overly broad and abstract questions, private corporate spend management company Ramp regularly releases its own estimates for AI adoption based on extracting text from billions of aggregated, anonymized transactions from over 30,000 businesses using Ramp. That data suggests that AI adoption has actually become meaningfully more pervasive over the past year with sectors like Technology, Finance, and Manufacturing leading the way. Figure 28: Adoption rates showing material increases across key sectors including Technology and Finance Source: Canaccord Genuity, Ramp An inescapable question since the advent of generative AI has been 'is this a revenue accelerant or an efficiency driver?' The answer is both, in our view, but who is answering the questions (consumers, SMBs, large incumbent enterprises) could make all the difference.

In the consumer realm, AI is already rewriting the texture of daily life: students lean on ChatGPT for tutoring, travelers turn to AI-powered concierges like Perplexity to plan trips, gamers use AI to generate mods and storylines, and creators remix music or video clips with generative tools that would have been unthinkable two years ago. These behaviors are more than fringe but represent a mass-market expectation that digital tools should be conversational, personalized, and adaptive.

On the enterprise side, AI copilots are changing how software is developed and maintained, from GitHub Copilot writing boilerplate code to GitLab and JFrog embedding AI into CI/CD pipelines. Security leaders are deploying AI-driven SOCs that can triage alerts or remediate incidents in real time. In customer-facing domains, enterprises are embedding AI recommendation engines and personalization systems directly into the product experience, turning what was once a back-office analytics function into a front-line growth driver. Even heavily regulated industries like healthcare and finance are experimenting with synthetic data generation to accelerate model training while maintaining compliance.

AI clearly is not a monolithic adoption story. For investors, the question has shifted from whether AI has utility at all to how it will scale across end markets, business sizes, and industry verticals. We think it's worth examining how these adoption vect ors differ in more detail, what this could mean for pricing and distribution, and where the software landscape may be headed as AI moves deeper into workflows and business models.

AI adoption is not uniform in part because the incentives to harness AI vary across user groups and business sizes. The same underlying technological breakthroughs are consumed in sharply different ways depending on the size, complexity, and regulatory environment of a business. For SMBs, the emphasis is on simplicity and immediate utility: off-the-shelf copilots embedded within SaaS applications that automate tasks without requiring in-house expertise. For these SMBs, AI helps resource-constrained teams do more with less, which ultimately enables faster business scale and better revenue capture. Enterprises, in contrast, focus on integration and compliance, with AI deployed as a deeply embedded capability that sits inside existing workflows and governance frameworks. For most of these large incumbent enterprises, AI adoption is predominantly framed as a means toGusto drive efficiency without totally transforming existing operations.

Consider workflow automation with generative agents. SMBs are already leaning on HubSpot assistants to manage campaigns and Shopify bots to optimize merchandising. These tools substitute for headcount and enable smaller firms to 'punch above their weight.' Enterprises approach the same use case through a different lens: they benefit more from domain-specific agents that can operate at scale and integrate across complex estates. Figure 29: HubSpot 's AI Assistant Breeze enables automation of complex workflows across sales, marketing, and service Source: Company site

The knowledge management space showcases how the same underlying technology (Retrieval Augmented Generation, or RAG) can be employed through split approaches. SMBs rely on turnkey integrations into Slack, Notion, or Intercom to make internal knowledge searchable without standing up IT projects. Enterprises, on the other hand, are more commonly deploying bespoke systems that sit on top of large internal data lakes while keeping existing compliance controls and access management concerns in mind. For these enterprises, the challenge is less about access to information but about the trustworthiness and security of those results at scale.

Source: Company site Human resources and talent management reflect a similar dichotomy. SMBs have long been underserved in recruiting and training, but AI copilots are beginning to fill that gap with resume screening, job description generation, and employee onboarding flows built directly into SaaS HR suites like Gusto or Rippling. This gives existing employees more bandwidth to focus on core revenue generating efforts while enabling faster hiring cycles by providing access to HR expertise that would otherwise be unaffordable. Enterprises still lean into those capabilities while also taking more of a strategic approach by identifying skill gaps across thousands of employees, personalizing learning pathways, and even predicting attrition risk by analyzing engagement signals. For large organizations, the payoff is about efficient deployment of human capital at scale.

Source: Company site Adoption patterns diverge in technical domains like software development as well. For SMBs, AI copilots and nocode 'vibe coding' platforms allow founders to ship applications without dedicated engineering teams, lowering the barrier to entry and blurring the line between technical and non-technical roles. For enterprises, copilots are being embedded into development platforms and tied into CI/CD pipelines, governance frameworks, and security scans. The focus is not labor substitution, but amplification: ensuring that thousands of developers can code faster without sacrificing compliance.

SMBs typically consume AI security passively, through pre-packaged capabilities in endpoint protection or managed services. CrowdStrike's Falcon Go or other SMB -friendly SIEM platforms deliver 'good enough' AI -driven protection without demanding additional investment. The use of AI enables smaller firms to enjoy the benefits of better security that may have previously been out of economic reach, in turn supporting faster scale. Enterprises, however, are experimenting with layering machine learning models onto petabytes of telemetry to autonomously triage incidents or even remediate threats in real-time.

Source: Company site To tie this together, SMBs and enterprises have both significantly increased AI adoption over the past two years, each adopting AI with different approaches. Because SMBs are typically more resource-constrained, the opportunity for efficiency to in turn drive improving revenue growth and faster scale is (at the margin) more impactful. Enterprises can take more time to ramp up adoption within existing business processes while requiring more thought around integration and governance but have greater relative benefit when applying AI to existing data assets at scale. In many ways, AI is a great operational levelling field for businesses, and the rapid growth from many AI natives in recent months is a testament to this. Incumbent large enterprises with differentiated data assets are in a strong position to improve their offerings by layering in AI, but our view is that over the next decade AI will create significant disruption to established market players today.

There's been plenty of investor discourse lately about the potential for AI agents to disintermediate existing SaaS incumbents as more execution moves away from an end user logging into and working within the four walls of an incumbent platform versus an agentic layer owning more of that execution. We think this 'death of SaaS' narrative is somewhat overstated, at least in the near term. Distribution, data rights, and embedded workflows remain durable moats and offer opportunities for incumbents to defend their turf while innovating with AI in their own right. Historically, vertical SaaS earned durable positions by encoding industry-specific workflows. Agentic AI frameworks expand the scope of what software can accomplish: the same vendor can now perform work, not just track it, capturing not just traditional software budgets but also slices of labor budgets. That enlarges TAM and arguably shifts the competitive conversation from 'feature parity' to 'who owns outcomes?'

Yes, vertical AI does put pressure on incumbents, especially where the 'system of record' was the moat. If a challenger uses AI to do the work (review the contract, settle the invoice exception, resolve L1 tickets) and prices on outcomes, the incumbent's per-seat module can look expensive and underpowered. To be fair, engagement and pricing models are already shifting for incumbents. But in theory, over time, decision automation can migrate value from the record keeper to the executor. But incumbents still start with real advantages that could arguably compound in an AI era rather than erode:

 Distribution & embedded workflows. Incumbents already sit in the flow of work. If they integrate agents natively (and not as superficial add-ons), they can upgrade the job-to-be-done without asking customers to re-platform.  Ability to evolve engagement and pricing models. As vertical AI fragments point solutions, incumbents can re-bundle into outcomepriced suites (e.g., 'claims closed,' 'tickets auto -resolved,' 'orders delivered on -time'), preserving ARPU with new value metrics.  Data rights, governance, and trust. Vertical challengers often need months of integration and data access; incumbents already hold high-fidelity, labeled workflow data under enterprise agreements. Turning that into retrieval, simulation, and fine-tuning AI assets remains a defensible path, provided they invest in quality and guardrails.

That all said, we think it's worth examining how newer agentic layers are challenging incumbents, what's worked so far, and how the competitive environment is changing in real-time.

EliseAI (real estate): EliseAI builds AI leasing agents that plug into property management systems, automating tenant communications, scheduling, and maintenance requests. The value proposition for landlords is higher conversion rates on leads, faster response times, and reduced staffing needs. The inherent challenge is that success hinges on the customer changing how leasing agents work as well as trusting AI to handle sensitive tenant interactions. In a human-driven services model, there is a good amount of workflow inertia. EliseAI's strategy of selling software to incumbents helps the firm build a growing foothold in a large market, even if it doesn't fully solve for structural changes in end-user behavior.

Replicant (contact centers): Replicant offers AI-powered voice agents that automate common call center interactions. For enterprise customers, this means labor savings, reduced handle times, and the ability to scale up and down instantly. Because Replicant sells into existing operators, it competes head-on with incumbents like Genesys or NICE, and must prove integration fidelity with existing telephony and CRM stacks. Replicant's approach allows the firm to go after a massive CCaaS TAM but places more pressure to solve for distribution while competing against incumbents with deep relationships that could also co-opt the technology by launching their own AI offerings.

Harvey (legal): Harvey has emerged as a flagship example of vertical AI in the legal sector. Rather than selling generic copilots, Harvey builds models fine-tuned on legal data and embeds them directly into the workflows of law firms and in-house counsel. Early deployments have focused on tasks that are both labor-intensive and relatively structured like contract review, discovery, and summarization. Harvey offers 'expertise in a box,' while for large enterprises, it positions itself as a lever on billable hours. The challenge is navigating trust, regulatory standards, and liability. It's no secret that the legal space has historically been a technology laggard.

Hippocratic AI (healthcare): Hippocratic AI is pursuing a bold vision: AI agents that can serve as 'nurses in the cloud,' handling pre -op instructions, post-discharge monitoring, and triage calls. The company explicitly positions itself as a 'safety -first LLM,' trained on clinical gu idelines and audited against stringent benchmarks. By targeting the labor bottleneck in healthcare (nursing shortages and patient engagement gaps), Hippocratic reframes AI not just as an efficiency tool but as a potential solution to systemic capacity constraints. The hurdles are obvious: regulatory approval, liability, and integration into electronic health record systems. Still, if successful, Hippocratic could shift cost structures in one of the largest global industries by capturing not just software spend but labor line items.

EvenUp (legal/insurance): EvenUp applies generative AI to personal injury and insurance claims, producing demand packages that would normally require hours of paralegal and attorney time. By automating the narrative construction and document prep process, EvenUp enables firms to process more cases with less overhead. Its growth demonstrates how vertical AI can turn 'non -billable' or lower -margin work into scalable, margin-accretive throughput. As with other vertical operators, the model depends on building trust in outputs, handling sensitive personal data securely, and navigating liability frameworks. New entrants with agentic capabilities are essentially in a race to reach a critical mass of execution. If a competitor can handle a large enough share of a workflow that customers begin to rely on it as a system of action, this could decisively shift the balance of power with major incumbent players. This is still easier said than done, and we foresee assimilation as a likely outcome for many, as large incumbent software platforms with deep pockets acquire leading agentic vendors to reinforce market positioning.

Much of traditional SaaS economics were defined by seat-based licensing structures which were generally well-liked by customers due to the predictability of revenue. AI adoption is potentially destabilizing that model, as value accrues not to the number of users logging into a dashboard but to the outcomes the system can deliver. For investors, this evolution has meaningful implications for predictability of revenue, gross margin structure, and the defensibility of incumbents versus challengers.

At the infrastructure layer, pricing still follows a metered model. API providers like OpenAI, Anthropic, and Cohere charge on the basis of tokens consumed, while GPU cloud providers meter access by minutes or GPU hours. Enterprises experimenting with direct model calls or custom fine-tunes have learned to internalize these costs, often passing them through to customers as a line item of usage. SMBs, by contrast, rarely contract directly with model vendors; they consume tokens indirectly, embedded in the SaaS products they already use. This split mirrors the broader adoption curve: enterprises care about cost transparency and optimization, SMBs care about packaged value.

At the application layer, copilots have largely been priced as add-ons to existing SaaS seats. Microsoft 365 Copilot, GitHub Copilot, Salesforce Einstein, and Adobe Firefly all follow a similar logic: layer AI on top of a well-penetrated seat base and charge a predictable premium, often $20 -30 per user per month. For incumbents, this strategy has two virtues: it preserves ARR predictability and drives ARPU expansion without requiring a wholesale rethink of billing. It also ties the AI benefit to existing workflows, blunting the entry of challengers. The risk, however, is that value delivered is not uniform: some users may generate thousands of AI queries per week while others hardly use the feature, raising questions about fairness and sustainability of flat-rate per-seat premiums.

From a monetization perspective, platforms layering in agentic AI can begin to incorporate consumptive or outcome-based pricing into the revenue model, which the customers typically don't mind because it represents a minor line item of their total spend an d they end up getting a lot more value out of the platform. We'll see how that conversation develops over time as that agentic line item grows, but we think agentic further extends the runway of pricing power available to these app titans. It also helps to provide an answer for one of the existential debates around seat-based pricing models -what do you do when you run out of headcount? Seat-based pricing. Even if headcount begins to again grow more materially within target customers, it's frankly tough to get comfortable investing in a name that requires an inflection in seat

growth for the stock to work. In some ways, even if agentic doesn't play out to the full extent that we might hope, it's creating a nice opportunity for these platforms to begin diversifying the revenue model towards consumptive or outcome-based pricing which could form the foundation for the next leg up for some of these stocks. Figure 33: Outcomes-based pricing could transform SaaS monetization

Source: Insight Partners These models expand TAM by reaching into labor budgets but come with operational complexity: revenue becomes more variable, gross margins depend on compute efficiency, and outcome verification must be robust enough to win customer trust. Looking ahead, we see a hybrid model future emerging blending traditional subscription revenue with increasingly consumptive elements. The likely equilibrium is not a wholesale move away from subscriptions, but rather a layered model where a stable base of recurring revenue is augmented by elastic usage charges. We view this as a win-win evolution for both customers and vendors.

The rise of generative AI and autonomous agents is reshaping cybersecurity into one of the most visible theaters of dual-use tension. On one side, adversaries are adopting AI to lower the cost of launching sophisticated campaigns, from mass phishing and deepfake-enabled fraud to polymorphic malware that evolves faster than traditional defenses can adapt. On the other hand, security practitioners are embedding AI into their platforms to process vast amounts of telemetry, detect subtle anomalies, and automate responses at a scale that human analysts alone cannot sustain. The result is a rapidly escalating race: attackers armed with self-learning tools probing for weaknesses, and defenders racing to harness the same technologies to shrink timeto-resolution and restore an advantage.

On the offensive side, the use cases are already fleshed out. Generative models allow threat actors to produce convincing social engineering campaigns in seconds, removing linguistic tells and dramatically increasing hit rates. Even more troubling are adaptive attacks where AI-enabled systems are deployed to interact with enterprise IT stacks in real time by altering tactics on the fly. With these capabilities now in the hands of adversaries, the effectiveness of static, rules-based security architectures is quickly eroding. Meanwhile, the rise of large language models and their integration into enterprise workflows has created a new class of vulnerabilities. Prompt injections (hidden or malicious instructions embedded in documents, websites, data streams) can essentially hijack model behavior, leading to data exfiltration or unintended actions with adverse consequences. What's more, when those models are wired into agents capable of taking real-world actions through APIs and enterprise systems, the risks compound. A compromised instruction is no longer just an errant response; it can become a

misconfigured network, a fraudulent payment, or a malicious code commit. Figure 34: Indirect prompt injections raise cybersecurity stakes by obscuring malicious requests in otherwise innocuous email attachments or saved files

Source: Palo Alto Networks On the defensive side, vendors are moving quickly to adapt to their approaches to protect against these new, dynamic threat vectors as well as to integrate AI into own platforms. AI is increasingly central to the modern SOC, where it filters billions of daily signals to expose the handful of incidents that merit escalation. By learning behavioral baselines across users, workloads, and endpoints, AI can spot deviations that would elude signaturebased detection. What's more, AI is beginning to close the loop between detection and remediation. Early deployments show AI agents capable of quarantining compromised devices, rolling back faulty deployments, and even patching vulnerabilities in close to real time. Beyond detection and response, AI is enhancing identity and access security through continuous, context-aware authentication, and it is enabling vulnerability management teams to triage based on the intersection of exploit intelligence and asset criticality.

Through its extensive suite of offerings both within and beyond the Falcon platform, CrowdStrike delivers comprehensive cybersecurity solutions designed to address the evolving risks introduced by AI. The company not only integrates AI across its products but also positions itself as a protector of the entire AI workflow -from securing the underlying data layer to orchestrating workflow automation. AI is central to its strategy, driving automation in threat detection and enabling 'agentic' SOC capabilities that enhance response speed and resilience against breaches. With the recent acquisition of Pangea, CrowdStrike is doubling down on this focus, advancing toward the launch of its AI-driven Detection & Response product, a critical pillar in its push to capture the growing Next-Gen SIEM TAM ( see more here ).

SentinelOne's cybersecurity offerings go hand -in-hand with AI capabilities. With their Singularity platform for autonomous cybersecurity, AI sits as a key driver in reducing the number of human agents needed to maintain a secure platform. With the recent acquisition of Prompt Security, the company seeks to compliment current AI capabilities while moving into securing GenAI apps and AI agents . We see this as a key strategy move that should benefit the SentinelOne as the need for securing GenAI and AI agents becomes more pertinent.

Cato Networks is one of the top private cybersecurity providers on the leading edge of AI innovation in security. With an already established platform offering end-to-end security, Cato offers autonomous visibility and control through their AI driven solutions. With a wide variety of AI driven solutions in their portfolio, Cato covers all of the bases for securing enterprise AI usage.

Another leader in the private cybersecurity space is Cohesity. With their partnership with NVIDIA, Cohesity expands their GenAI products on top of the NVIDIA AI Enterprise. The company has already proven itself with Zero-Trust Data Security Principles and AI Powered Data Insights and looks to continue market leadership through their partnership with NVIDIA.

When looking at the offensive threats of AI, email attacks sit at the top of people's minds. Abnormal Securities hones in on this weakness in the security stack and offers new and improving AI Security Agents to help customers prevent this type of attack. In a world where the offensive threats are becoming better seemingly as fast as the defensive solutions, automated processes and agentic solutions are needed to keep up. With features that allow data ingestion and export to/from a variety of sources, Abnormal allows for seamless integration with other solutions (see below).

Source: Company Site

Armis is another private cybersecurity player that in consistently innovating within the AI security arena. With their new releases of Armis Centrix for Vulnerability Management Detection and Response as well as Armis Centrix for Application Security, they offer important capabilities like agentic scanning asset mapping, and an AI built system to secure AI. Having crossed several key financial milestones ($300M in ARR and securing multiple billions of assets), Armis has proved their competitive edge in the cybersecurity space.

Chainguard serves a unique purpose in the AI security stack. With a focus on container images and securing image applications, Chainguard helps defend customers' software artifacts and key image data in securing AI applications. With Chainguard Containers, Libraries, and VMs, they are able to leverage malware resistant libraries, container images and hosts to optimize for customer needs.

Huntress offers AI security specialists that provide the key services needed for safeguarding AI and ML systems. These specialists actively identify vulnerabilities that hackers look for and implement strategies to mitigate breaches. Coupling with their safeguarding systems is their array of platform EDRs, allowing Huntress to continually monitor customer systems and back it with AI-assisted SOC agents. Huntress continues to invest in their AI-assisted SOC given its growing importance and key spot in the cybersecurity stack. On the whole, this dynamic suggests that security budgets will increasingly tilt toward platforms that harden the AI supply chain, monitor model behavior, and safeguard the emerging 'decision layer' where enterprises are increasingly delegating judgment to machines as a means of improving time-to-resolution while becoming more resource-efficient with existing teams.

Improvements in and the proliferation of AI have dramatically changed how investors view software markets over the past two years. We get a lot of questions about where quantum computing fits into this picture. The short answer is that it's really more about how each complement (rather than compete with) one another. The following section explores these differences in greater depth to clarify where quantum stands apart and how it fits within a broader technological portfolio.

AI is a software-first, data-driven paradigm built atop classical computing infrastructure, delivering measurable returns today across search, recommendation, automation, and analytics. Quantum computing, by contrast, is a hardware-first reimagination of how computation itself is performed -offering long-term promise in domains that are intractable for even the most advanced classical systems, such as combinatorial optimization, quantum chemistry, and cryptography. AI is already embedded in enterprise workflows and is beginning to be monetized at greater scale, whereas quantum is still early-stage but potentially transformative in highly specific verticals. As adoption curves diverge, so too do investment frameworks: AI is a story of platform scale and data advantage, whereas quantum offers a targeted entry point into computational white spaces where classical and AI tools run out of steam.

The advent of GenAI has significantly influenced quantum computing over the last couple of years, particularly in accelerating the development of hybrid quantumclassical solutions. D-Wave Quantum has partnered with companies like Zapata AI to combine the power of generative AI with quantum computing, focusing on applications such as drug discovery and molecular design. These collaborations have led to breakthroughs in training large language models (LLMs) and improving the efficiency of AI workflows. For example, D-Wave's quantum processing units (QPUs) have been used to enhance LLM training, resulting in higher-quality, drug-like molecular structures for pharmaceutical applications. This integration of quantum computing with GenAI has opened new avenues for solving complex problems in industries like healthcare and materials science.

From a commercial perspective, quantum computing is still very much in its nascency. We expect the space will truly grow into its own in the 2030's driven by advancements in hardware, software, and commercial adoption. Within the broad quantum landscape, quantum annealing is much more ready than gate models to solve problems in a commercial setting. D-Wave has already demonstrated quantum supremacy on a useful real-world problem, solving a complex magnetic materials simulation in minutes that would take nearly one million years on a classical supercomputer. The company's sixth-generation Advantage2 system, with over 4,400 qubits, is commercial-grade and capable of addressing real-world use cases in optimization, materials simulation, and AI. The growing adoption of quantum computing by enterprises and governments, coupled with increasing investment in quantum research and development, suggests that quantum computing will achieve widespread impact and critical mass within the next few years. Market observers p redict broader quantum commercial impact potentially materializing in the 2030's.

Key Players: D-Wave, IBM (Quantum Segment) IonQ PsiQuantum Source: Canaccord Genuity Research Key Players: NVDA, Microsoft, OpenAl, Anthropic

The past two years have confirmed that we are in the midst of a global arms race in artificial intelligence. Setting aside the longer-term possibility of AGI, the stakes in this AI race remain daunting. AI represents both an economic productivity lever as well as an enabler of national security, scientific research, and industrial policy. While this is a global race, the competition has crystallized most clearly between the US and China, the two nations with the deepest capital markets and most expansive ambitions today for AI deployment.

It's hard not to establish narrative links between the Space Race in the 60's and 70's to the global AI race today. Both eras feature technological largesse, geopolitical uncertainty, national pride, and massive capital outlays in the pursuit of innovation. Just as the Space Race helped ignite technological and industrial progress for both participating countries, this AI arms race could prove to be a powerful forcing function to encourage near-term innovation. In the United States, the combination of frontier model labs, hyperscale cloud platforms, and a robust venture ecosystem has propelled the pace of innovation. While China has been more aggressive with central planning initiatives, Washington has also begun treating AI as a matter of national competitiveness, evidenced by export controls on advanced chips, heightened scrutiny on outbound capital, and growing investment in domestic semiconductor and compute infrastructure. The US advantage lies in the integration of private-sector innovation with state-level policy, a dynamic reminiscent of the Cold War era when defense procurement accelerated aerospace and computing breakthroughs.

China, meanwhile, has placed AI at the center of its industrial and geopolitical agenda. State planning documents explicitly call for global leadership in AI by 2030, and Beijing is mobilizing national resources to build sovereign capabilities across chips, algorithms, and data infrastructure. While Western sanctions have constrained China's access to the most advanced GPUs, domestic alternatives and workarounds are progressing at a rapid clip. Moreover, China's large domestic market provides both the training data and commercial runway for AI adoption at scale. The government's ability to direct demand and subsidize investment ensures that even partial technological disadvantages can be offset by sheer speed of deployment.

Washington's export restrictions on Nvidia's most advanced GPUs were intended to act as a brake on China's frontier ambitions, cutting off access to the chips that fuel the training runs of today's largest models . Prior to the restriction being imposed, China accounted for ~20% of Nvidia's revenue , with the restrictions causing that share to drop to as low as 6% now. The controls have indeed raised China's cost of compute by forcing developers to stitch together smaller clusters, lengthen training cycles, and lean more heavily on software efficiency. Yet the story is less about outright denial than about delay and diversion.

DeepSeek's rise (which represented a 'Sputnik' moment) is a case in point: by combining mixture-of-experts architectures with aggressive distillation, its engineers showed that competitive performance can be achieved without the latest Nvidia GPUs. At the same time, domestic chip programs from Huawei and others, though behind in raw horsepower, are steadily improving and are increasingly 'good enough' for inference at scale.

Source: Artificial Analysis As we look at the Frontier Language Model Intelligence that compares the US and China over time, the clear trend is the US leading, but with China slowly inching closer to competing with the US's top providers. In our view, this global competition isn't slowing down and will only create more incentives for each nation to invest more in developing better chips, models, and data assets.

While the US and China are the most prominent competitors in this race, they are far from the only participants. Europe, while hampered by a fragmented market and regulatory overhang, is shaping the rules of engagement through initiatives like the EU AI Act and exerting influence by defining global norms around safety and compliance. Japan and South Korea, with their strong industrial bases and semiconductor expertise, are re-emerging as relevant players in the ecosystem. India, with its scale of software engineering talent and rapidly digitizing economy, is positioning itself as a critical node in AI services and model deployment. Even smaller countries, from the UAE to Israel, are carving out niches through targeted state investment, talent recruitment, and sovereign compute strategies.

| 2025E   | CapEx ($B)   |
|---------|--------------|
| AMZN    | $121         |
| GOOGL   | $85          |
| MSFT    | $78          |
| META    | $69          |
| Total   | $353         |

The AI race across the Tech sector continues to intensify, led by a handful of companies -Amazon, Google, Meta, and Microsoft -which have accelerated investments to establish early leadership in key AI-native areas. Collectively, these tech giants are projected to spend more than $350B in 2025 on CapEx, with the majority directed toward AI-related initiatives such as scaling key infrastructure and integrating generative AI models into core products, complementing additional investments in attracting top-tier AI talent. While the mega-cap tech names dominate the AI investment cycle, smaller companies are also actively integrating AI across their platforms, fueling rapid innovation in personalization, automation, and overall platform efficiency. Nearly every company in our Internet coverage is embracing AI as a core platform tool for driving (1) internal operational efficiencies and (2) new revenue opportunities, including the integration of AI into existing offerings, or the creation of entirely new AI-native products and services. Below are some recent developments and specific examples:

 CapEx investments to fuel the next leg of AI leadership as competition heats up: AI-related capital investments continue to be a core theme across our largecap tech coverage, with Amazon, Google, and Meta all indicating higher levels of investment over the next 1218 months. Meta's Superintelligence Lab and broader infrastructure upgrades will drive $66-72B in CapEx spend this year and around $100B in 2026 as Mark Zuckerberg's vision of AI surpassing human intelligence increasingly shapes the platform. Google raised its FY25 CapEx outlook to ~$85B, reflecting additional investments in its Cloud business, which as of Q2 maintained a customer backlog of ~$106B. Looking ahead, the company expects further increases in CapEx in 2026 due to Cloud customer demand and other growth opportunities. Similarly, AWS, which has a sizeable ~$195B backlog, c ontinues to be the primary driver of Amazon's CapEx, as the company invests in custom silicon and infrastructure, in addition to ongoing investments in its fulfillment and transportation network, including robotics and

automation, to support long-term growth and operating efficiency.  Cloud offerings represent a bridge to cutting-edge AI tools: The rise of generative AI is accelerating cloud adoption and prompting companies to modernize their infrastructure to support advanced AI capabilities. For most businesses, launching generative AI efforts independently presents significant hurdles, including high upfront infrastructure costs, limited access to specialized hardware like GPUs, and a shortage of skilled talent. In contrast, major cloud providers such as AWS, Microsoft Azure, and Google Cloud offer scalable tech stacks with access to comprehensive AI product portfolios, effectively democratizing AI. Several companies in our coverage are capitalizing on existing or expanded partnerships with cloud providers to integrate the latest AI Figure 40: Spotify has a new voice search interface that lets you say 'Play my Discover Weekly,' or 'Show Calvin Harris' Source: TechCrunch

innovation. Spotify expanded its partnership with Google Cloud in 2023 to explore generative AI tools, initially focused on enhancing user experiences through personalized recommendations and safer content discovery. However, in 2Q25, management noted GenAI was also improving backend infrastructure, boosting efficiency, and accelerating product delivery. As AI continues to evolve, cloud platforms are emerging as strategic accelerators, lowering barriers to entry and allowing companies to rapidly experiment, deploy, and scale AI-driven innovation across both customer-facing and operational domains

 Digital advertising platforms continue to integrate AI solutions across the tech stack with a focus on ROI for advertisers: Across our digital advertising coverage, companies are increasingly leveraging AI-based innovation to deliver measurable ROI improvements for advertisers and support monetization tailwinds. These innovations include the integration of AI into bidding, planning, creative generation, and measurement workflows, driving improved performance, cost efficiency, and ROAS. Larger players like Meta and Google continue to expand their proprietary AI architecture, layering in new tools and services to their next-generation platforms, which has contributed to accelerating adoption and monetization. Meanwhile, smaller platforms like DoubleVerify, Viant, and Nexxen are enhancing their suite of offerings by introducing products designed to streamline workflows through automation and improve performance via more robust targeting and creative. A prime example is Viant's AI product suite, which combines to ols for automated bidding, media plan creation, performance insights, and optimization. Additionally, earlier this year DV debuted

Authentic AdVantage, an offering that combines DV's core verification solutions with Scibids AI, enabling advertisers to better understand impression quality and optimize for cost and performance, and Nexxen launched nexAI, an AI assistant and insights tool that management expects will transform campaign execution and monetization.

 Integration of natural language search helping to improve the user experience for streaming platforms: Streaming names in our coverage such as Spotify and Netflix are leveraging the latest advancements in LLMs to improve core product experiences and content recommendations for users. One key area of innovation is the integration of natural language conversational queries, which allows users to interact with platforms through dialogue-based interactions rather than traditional keyword search. This shift improves content discovery by enabling users to express preferences in a more natural and flexible manner (e.g., 'Show me something like Squid Games but funnier'), thereby reducing friction in the search experience and increasing time spent on platform. This also creates a new dataset for these platforms, capturing the specific language and context users employ when searching for content. This technology and the related data mark a shift from predictive user experiences, where platforms suggest content based on historical patterns, to reasoned experiences, which interpret both user behavior and conversational input to enable personalized, context-aware recommendations.

Figure 41: Etsy is utilizing a blend of human and AI-powered recommendations to create a more personalized experience for shoppers Source: Etsy -  eCommerce companies leveraging AI to create a customer relationship flywheel: While early applications of AI in eCommerce were largely confined to customer service chatbots and basic product recommendation engines, the technology has rapidly evolved to become a core driver of innovation across the entire customer lifecycle for both buyers and sellers. Companies like Etsy are using AI to deliver more personalized marketing content to potential customers, and several platforms are actively retooling their websites and search algorithms to better interpret and respond to user preferences. With AI, these platforms can analyze past shopping behavior and search queries, then dynamically

align product descriptions and recommendations to match individual user intent. This approach enhances personalization, improves search relevance, and ultimately drives higher engagement and conversion rates. This is also further enhanced by the use of AI to create immersive shopping experiences, such as Wayfair, which recently deployed Decorify, a virtual room styler powered by AI, to help users visualize products in their own spaces. AI is also transforming backend operations for companies like Amazon, which is utilizing AI across its logistics infrastructure, including (1) Wellspring, a generative AI mapping technology that enhances route planning and spatial analysis; (2) a sophisticated AI-driven demand forecasting model that powers its supply chain decisions; and (3) agentic AI capabilities designed to improve the performance and autonomy of its robotics fleet. Figure 42: Ranking our covered large- and mid-cap companies across 7 different AI dimensions suggests that AMZN, GOOGL, and META lead in AI Source: Canaccord Genuity estimates, Company reports

| Ticker   | Detail       | 6M%   | 1Y%   | 2Y%   |
|----------|--------------|-------|-------|-------|
| IGV      | Software ETF | 41%   | 29%   | 64%   |
| WCLD     | Cloud ETF    | 21%   | 11%   | 17%   |
| NVDA     | Nvidia       | 89%   | 45%   | 304%  |
| AIQ      | AI ETF       | 57%   | 35%   | 85%   |
| S&P      | Index        | 33%   | 18%   | 56%   |
| NASDAQ   | Index        | 31%   | 25%   | 78%   |

We think any lingering bear arguments surrounding generative AI's efficacy have been sufficiently debunked, as its proliferation has only accelerated in the interim. Companies across all industries (including Software itself) have been working to incorporate generative AI within various business units, namely 1) the contact center, 2) IT service management teams, 3) within go-to-market teams (both inbound and outbound, and more, in an effort to drive efficiencies both at the bottom line as well as accentuate growth efforts at the top line. However, much of this adoption has yet to fully manifest in financial results, and it's still unclear if management teams are taking a prudent approach for investors, or if the intangible benefits of AI perhaps outweigh outright monetization. We expound on some of the key thematic discussions regarding generative AI in the bullets that follow, but first, we'd like to address the omnipresent argument that AI is the 'SaaS -killer'.

We think it's pretty clear that, to date, much of the investor value attributed to generative AI has accrued at the hardware and infrastructure layers, with Software being a relative laggard for the most part. Cloud stocks have returned roughly +21% over the last 6 months, compared to the Nasdaq's + 31 % and S&P 500's + 33% over the same period. The narrative that's circulating is that generative AI (in particular, 'vibe coding') is the 'SaaS -killer', as customers can leverage low -code/no-code developer tools to effectively bring software development in-house and circumvent incumbent vendors to save costs. Frankly, we don't see this as a truly feasible threat for several reasons. First, Enterprises are extremely risk averse. Handing over troves of proprietary first-party enterprise data to unsecure AI tools doesn't seem likely ; there is a huge need for ironclad data privacy, governance, and compliance that is all managed at the vendor level, and we don't think enterprises have

the domain expertise to achieve this. Second, enterprise tech stacks are incredibly complex (read: messy), replete with intertwined systems, technical debt, and often frequent turnover of the employees that actually manage this. Writing new code is one thing, weaving it into an existing tech stack seamlessly is a completely different ballgame, in our view, one that AI coding tools aren't equipped to handle just yet. Third, bringing these tools in-house is costly in the best of circumstances and near disastrous when they go wrong. In the AI arms race where business leaders are all competing to integrate AI into their existing businesses to stay ahead of the competition, there is little margin for error, either at the SMB or Enterprise level. Some of our further observations on AI within the Software universe include:

-  (Apps) Evolving top-of-funnel dynamics disrupts traditional PLG motions, but the show goes on. AI as a search vehicle has started disrupting traditional search, as legacy SEO practices aren't optimized for new agent queries but rather human eyes. HubSpot admittedly called out that since late 2022, inbound traffic from traditional content (i.e. blogs) has been declining as customers are turning to AI answer engines, but they've pivoted by investing in people -driven channels Figure 44: Shopping through answer engines like ChatGPT product recommendations accounts for ~60% of online purchases now Source: OpenAI, BigCommerce

(podcasts, YouTube channels, newsletters, etc.), which are seeing traction. Similarly, Monday.com saw a slight hiccup in top-of-funnel adds as search disruption muddied the algorithm for its SMB cohort. Bringing this all together, many vendors were caught flat-footed by the addition of AI as a channel and the corresponding impact on traditional search, but we think it represents more of an evolution than existential threat. As such, we see any top-of-funnel pipeline disruption, particularly for PLG-led business, as transitory at best.

 (Apps) Evolution of seat-based models to gradually incorporate consumption. In earlier days, there were fears that the growing usage of generative AI tools would disrupt the seat-based pricing model paradigm within Software in favor of one that looked more consumption- or outcomebased. While we don't think that has necessarily c ome true, it's clear that the way companies are thinking about pricing has changed to include more hybrid-based elements. Some notable examples within our coverage include Atlassian (TEAM), HubSpot (HUBS), ServiceNow (NOW), and Salesforce (CRM), all of which have kept traditional seatbased pricing models for access to the core platform, all while democratizing usage of generative AI elements through consumptive 'pay -as-yougo' usage tiers. We think the intersection of these two pricing models represents the best of both worlds for companies in that 1) vendors don't have to completely give up the stability and visibility of seat-based models, but also 2) can get generative AI solutions into as many hands as possible, priced in such

a way as to promote increasing usage and monetizing down the line as value is realized.  (Apps) AI answer engines' effect on e -commerce. Similar to SMB discoverability, the acceleration of AI answer engines is upending the typical ways that customers search for, compare, and ultimately purchase products online. At a recent event, we were surprised to learn that now nearly 60% of all online purchases originate within an answer engine (ChatGPT, Perplexity, etc.) While traditional SEO is optimized for product placement for human eyes, many brands have been caught flat-footed and are scrambling to get in front of customers (or rather, their AI agents by proxy) shopping through AI answer engines. This new channel has been maligned as a critical threat to traditional SEO, but we think the implications for e-Commerce firms within our coverage (such as Shopify (SHOP) and Commerce.com (CMRC)) are less existential. Rather, e-Commerce vendors have been dealing with a constantly evolving playing field (social

commerce, marketplaces like Amazon or eBay, etc.) for years, so we think they are perhaps some of the early movers in the space, and to them, AI answer engines are simply a new channel.

 (Apps) Customer Support, GTM, and Enterprise Search primed for AI augmentation. In this new agentic AI era, we think it's fair to say that high fidelity first-party proprietary data is essentially the new gold and oil rolled into one. Firms such as HubSpot (HUBS), Atlassian (TEAM), Salesforce (CRM), ServiceNow (NOW), etc. that provide a platform value proposition through sheer surface area within customers' tech stacks, as well as troves of first -party data for AI to feed off, are at a structural advantage. As such, while AI certainly has applicability across a broad swath of customer s, industries, and business units, the 'low hanging fruit' we've seen so far has been 1) in Customer Support roles (both customer facing and internal ITSM), 2) within GTM functions through hyperpersonalization and reduced content costs, and 3) within Enterprise Search,

Source: Datadog Figure 46: Malicious prompt injections have created urgency to buy cyber protection Source: Palo Alto Networks  where the intermingling of enterprise data breaks down legacy silos across organizations. AI certainly poses a threat to numerous legacy job functions, but within these industries, we believe incumbent platforms have dug themselves some pretty deep structural moats.

(Infra) Domain-specific agentic workflows emerge to enhance platform appeal: Within our infrastructure software coverage, some companies have begun to release domain-specific AI agents that accomplish more than just recommending action, but actually fully executing workflows. Datadog's Bits AI agents (with SRE, Dev, and Security variants) serve as one of the earliest large-scale attempts to bring domain-specific AI agents into the infrastructure software stack, moving beyond generic copilots toward specialized automation. This positions Datadog to capture incremental budgets by reducing operational toil, shortening incident resolution, and accelerating developer productivity by creating outcomes that directly translate into ROI for customers. GitLab's Duo Workflow o ffering (in private beta) has a similar aim but has a wider purview, spanning

from automatically running CI tests to implementing suggested changes and suggesting and completing architectural changes. In general, this is a relatively unique way for platforms with troves of valuable data to translate that industry expertise into what is not just a differentiated knowledge asset but an intelligent agent actively creating value in tandem with end users. Bigger picture, the vision is that instead of one general AI layer bolted onto existing tools, enterprises may increasingly adopt fleets of narrow, high-context agents that reduce toil, accelerate resolution, and create leverage across engineering and security teams.

 (Infra) As a new infra stack coalesces, consumption finally shows signs of a material ramp: For much of the past 18 months, AI infrastructure spend has been concentrated in GPU buildouts at hyperscalers and early adopters, while software consumption lagged. As enterprises move from pilots to production, a new infrastructure stack is forming as newer technologies like vector databases and model registries become more critical. As private valuations have soared, public market incumbents have been forced to re-evaluate their strategy and product roadmap for this AI era as well as fine-tune their messaging towards investors wondering why (in most cases) AI-related revenues have been relatively slow to take off. That dynamic is beginning to shift. We are seeing early signs of pullthrough across developer platforms (GitLab, JFrog), data infrastructure (MongoDB, Snowflake, Databricks), and observability/security vendors (Datadog, CrowdStrike, SentinelOne) as AI workloads require

end-to-end tooling. In our view, investors can think of this as the start of a more durable base of consumption as incumbents integrate more AI into their tech stacks and business models and as newer AI-native startups generate more revenue and become larger customers.  (Security) Supercharged bad actors and the rise of prompt injection attacks: Generative AI has lowered the cost and raised the sophistication of phishing, deepfakes, and malware creation, enabling adversaries to scale convincing social engineering campaigns and rapidly generate polymorphic code that evades traditional defenses. Beyond content generation, attackers are experimenting with adaptive attack strategies that use AI to probe defenses, learn responses, and dynamically alter tactics in real time, eroding the effectiveness of static

security models. Freshly emboldened bad actors have created more urgency to for buyers to invest in cybersecurity and for vendors to bring more capabilities into their platforms capable of protecting against prompt injections, model supply chain attacks, and agent exploits. Prompt injection occurs when an attacker crafts malicious input (text, image, code, or even metadata) to manipulate how an AI system interprets instructions. The classic example is telling a model to 'ignore previous instructions and' b ut the real danger comes when injections are indirect, or hidden inside web pages, documents, or data that an AI agent is instructed to fetch and process. As AI-enabled applications become more pervasive, the business risk associated with prompt injections continues to grow. Figure 47: Ranking our covered Applications universe across 7 different AI dimensions Source: Canaccord Genuity estimates, Company reports Figure 48: Ranking our covered Infrastructure and Security universe across 7 different AI dimensions Source: Canaccord Genuity estimates, Company reports

While the FinTech sector is generally associated with disruption, at least for now, we see less impact either positively or negatively on the sector coming from the introduction of generative AI. Many automation tools already exist in FinTech across a variety of business models including those that are payments-, software- and lending-centric. Importantly, a material regulatory backdrop is part of the larger FinTech sector ecosystem; and we believe it will be some time before regulators become comfortable with generative AI being used in most customer-centric activities. Still, we are seeing niche use cases for generative AI making their way into FinTech business models on an opportunistic basis. Clearly there are efficiency gains in adopting this technology on the back-end, but generative AI lends itself well as a tool when it comes to helping consumers with scenario analysis around topics such as down payment/monthly payments in mortgage and when it comes to driving internal efficiency gains.

-  Highlighting Dave and its new AI model . In Q2, Dave announced that it's in the testing phase of version 5.5 of its CashAI underwriting model. The new model fully incorporates the economics of the company's new fee structure and is trained on more than twice the number of features as the current model. With version 5.5 expected to be deployed later this year, we think the company could see further improvements in cutting out bad risk and improving delinquency rates. In our view, the new AI model should also support ARPU expansion by enabling higher average origination sizes while maintaining healthy loss rates.

As we look ahead, we continue to believe that generative AI can bring a lot to the table for the broader FinTech sector -credit algos can become smarter, payments can become more intuitive, and in software, platforms can become smarter. That said, we believe that FinTech could be a slower adopter of AI compared to other fast growth sectors in Tech -and this is due to the regulatory backdrop. Consumer protection, discriminatory lending practices and bank regulation make for a tricky path to adoption. While we believe that over time we will see more niche applications of generative AI emerge from FinTechs, we are not seeing this technology be a material game changer in the short to medium term at this point.

Source: Canaccord Genuity estimates, Company reports

Gaming companies leveraging AI to deliver more personalization: For the online gambling space, the biggest area where AI is impacting these businesses is their ability to continue introducing more personalized user experiences, including bet types, betting content, and promotions. AI also has a significant opportunity to foster more responsible gaming by detecting activity that represents a high likelihood of problem gambling, and companies are also leveraging AI to drive efficiency within their backoffice operations. For the video game industry, AI has the potential to democratize content and game development by enabling the text-prompted creation and editing of individual assets or complete game landscapes and mechanics.

 Gambling apps harnessing AI to create more personalized & efficient promotional offers: DraftKings (DKNG), Flutter (FLUT), PENN Entertainment (PENN), and Super Group (SGHC) are all, to varying degrees, using AI to personalize the types of bets that are surfaced to users on the home page and to personalize the types and amounts of promotional generosity offered to users. These companies are all also using AI to inform the setting of both pre-match and live odds.  AI being deployed for data collection & pricing: Sportradar (SRAD) is using computer vision to automate the collection of live sports data, starting with sports that have a very defined field of play that lend themselves to this type of data collection such as tennis. The company is also using AI to continuously refine its pricing capabilities for the setting of live odds within its managed trading services business unit and is also testing a genAI-powered chatbot that allows sports fans to quickly query historical facts & figures and create complex betslips based on recent player performance trends.

 AI tools may revolutionize video game development: Roblox (RBLX) has started to introduce tools to help creators with the game development process, but the most immediate uses of AI on the platform are (1) within the recommendation engine for content on the home page and (2) for moderating communications between users to ensure platform safety and identify inappropriate behavior. AI-powered assistants enriching the learning experience: For the EdTech industry, AI has a variety of use cases and impacts beyond the ability to quickly get in-depth answers on virtually any topic or question. Within the K-12 and Higher Education spaces, AI tools are serving as tutors and interactive study guides to help reinforce topics for students, including the ability to generate quizzes on any subject and then reinforce areas of weakness with supplementary content, although these tools are also being used to cheat on papers and other assignments. For professional development, AI is continuously changing the responsibilities and skills needed for a variety of jobs across industries, fueling greater demand for training and reskilling.

 AI fueling robust demand for professional training & reskilling: Udemy (UDMY) is in the process of transforming from an online content catalog to an AI-enabled reskilling platform, with one of the first steps being the introduction of a new AIfocused content bundle as it refines the merchandising of its courses for Enterprise customers. One of the most immediate ways Udemy is leveraging AI is the introduction of custom role play simulations that help employees practice a variety of situations in enriching and hyper-personalized ways, with potential use cases ranging from new managers practicing performance reviews, recently hired sales staff practicing their pitches for various products/services, and accelerated onboarding for customer service reps. The com pany's new MCP Server will also help organizations create more personalized learning journeys for their employees by embedding content from Udemy's library within AI apps like ChatGPT.

 Students & teachers benefiting from AI tools before, during, and after tutoring sessions: Nerdy (NRDY) has introduced a variety of AI-powered features to enhance the tutoring experience, including a suite of context-aware AI tools that provide real-time guidance to tutors and students during sessions, a Tutor Copilot that provides real-time lesson plan generation, and the ability to use transcripts of tutoring sessions or classes to provide test prep and practice problems. Figure 50: Ranking our covered companies across 7 different AI dimensions suggests that SRAD, RBLX, UDMY, and NRDY lead in AI High relevance Source: Canaccord Genuity estimates, Company reports Low relevance

AI has become both a growth driver and a competitive disruptor for digital transformation services firms. Historically, these businesses scaled primarily by adding people (labor leverage), but AI is changing that model by boosting delivery productivity through tools that compress the software development lifecycle, helping with coding, testing, documentation, and translating legacy code into modern developer languages. That dynamic is shifting their role from being primarily laborleverage driven toward becoming more IP- and platform-led via productized development accelerators and reference solutions. This shift is also changing commercial models, as clients are demanding faster time-to-value and measurable outcomes, which is catalyzing (a) outcomes-based (per resolution/deflection, conversion, uptime, etc.) and gain-share pricing rather than pure time-and-material, (b) more recurring/managed services, and (c) tighter data governance, security, and model observability baked into delivery. Net-net: AI expands the

addressable market for modernization and data/ML work, but it also pressures undifferentiated staff-augmentation models, positioning winners as those that pair domain expertise with proprietary platforms. AI is transformative for the industry in the below examples:

 Software development & modernization: Copilots for coding, testing, and documentation; automated code refactoring and translation for cloud migrations.  Digital experiences: GenAI-generated copy, images, videos, and personalized content for media, marketing, retail, and gaming.  Commercial innovation: Firms are packaging accelerators into fixed-price or outcomes-based offerings, often tied to KPIs such as resolution rate, CSAT/NPS, or conversion lift.  Operational intelligence: LLM-powered knowledge search across past design and development.  Customer service: (a) Agent-assist copilots (real-time retrieval, next-bestaction prompts); (b) conversational AI (chatbots/voicebots) with human hand-off; and (c) Auto-summarization and quality scoring of customer interactions.  Workforce management: AI-driven demand forecasting and scheduling optimization.

Source: Kratos

Source: AeroVironment

Within the Aerospace & Defense industry, AI adoption is expanding across verticals including UAS/C-UAS, Space Technology and Advanced Air Mobility. The most immediate impact is being felt both in the Drone and Space industries amidst greater US and allied government emphasis on global security. UAS/C-UAS technology utilizes AI to enable autonomous flight (even in GPS-denied environments), drone swarming capabilities, manned-unmanned aircraft teaming and improved target identification, threat prioritization, and strike execution in combat scenarios. Predictive AI is already enhancing space domain awareness by improving orbital satellite traffic management and collision avoidance via autonomous tracking of satellites, debris and potentially hostile spacecraft. Further, AI is enhancing autonomous data processing and analytical capabilities, which are directly relevant to EO satellites processing and deriving insights from greater volumes of highresolution imagery and lunar science missions conducting autonomous entry, descent and landing operations on complex off-world terrain. NASA

scientific research has been bolstered by AI-driven autonomous driving (robotic rovers like the future Lunar Terrain Vehicle), topographical analysis and hazard avoidance without input from a human operator. We additionally expect AI-driven automation to be implemented into the US air traffic control (ATC) network to reduce cognitive load on air traffic controllers in towers and enable safer travel throughout the National Airspace System. While not as immediate, we anticipate autonomous flight technologies to be applied to eVTOL passenger and cargo aircraft. However,

Source: Intuitive Machines

Source: Joby Aviation adoption remains dependent upon regulatory, safety and pilot union-related challenges.

 Defense primes and defense tech companies are using AI in drones for autonomous flight and strike capabilities to complement manned fighter jets. Under the Pentagon's Collaborative Combat Aircraft (CCA) program, companies like Kratos, Anduril, General Atomics, Lockheed Martin, Boeing and Northrop Grumman are developing autonomous, uncrewed jet drones to be operated alongside manned fighter jets. Aircraft iterations that are ultimately selected under the program will serve as 'loyal wingmen' for stealth crew ed 5 th and 6 th generation aircraft like the F-35, F-22 and F-47 NGAD system, among other advanced fighter aircraft like the F-15EX. CCAs are designed to remain under human command and control during missions to ensure collaboration and warfighters making final decisions on offensive strikes. However, they will leverage AI/ML to operate independently in certain situations to autonomously perform tasks like ISR, EW, aerial refueling and comms relay. CCAs are intended to extend the range and

capabilities of crewed aircraft in contested airspace, reduce the cost of performing high-risk missions and lower overall risks for human pilots.  AI's use is already widespread within UAS and C -UAS platforms, leveraging autonomy for both offensive operations and aerial defense against enemy drones. AI implementation into UAS technologies enables drones to navigate autonomously without human input or access to GPS. Drones utilize computer vision and radars to adapt in dynamic environments and avoid obstacles, leveraging AI/algorithms to change their route in response to adverse weather, potential threats or changes in mission objectives. This technology enables large numbers of drones to coordinate their behavior for 'swarming' tactics that can be used in saturation attacks that overwhelm an enemy's air defense systems.

 CUAS technology has benefited from AI's ability to fuse several sensor datasets at once, integrating radar, EO/IR cameras, RF scanners and acoustic sensors to better detect drones, recognize flight patterns, characterize drone type to identify weak points and continuously track multiple drones simultaneously. The use of several combined sensor modalities enables more accurate targeting for point defense and optimization of EW jamming and spoofing against incoming drone attacks.

 AI is already being used extensively in space to provide predictive analytics and change detection from Earth Observation data collected by remote sensing satellite operators. Spire Global's LEMUR constellation of 100+ cubesats ha s experienced rapid improvements in processing power and instrument capability, with a 10x improvement in satellite technology every five years, exceeding Moore's Law. Hardware improvements in computing power enable Spire's satellites to use AI for more onboard processing of raw RF data, which can be transformed into 'smart data' insights for applications including weather forecasting (with economic impacts), aircraft tracking (ADS-B/MLAT), and RF signals intelligence (SIGINT) for government clients. Customers are able to directly access these AI generated insights via Spire's API. Additionally, BlackSky Technology employs predictive AI and computer vision algorithms to power its own Spectra platform. Spectra offers subscription-based customers automated change and anomaly detection that leverages

AI-enhanced sensor fusion technology to provide 'tip -andcue' capabilities. This means that one sensor or data source utilized by Spectra can detect some form of suspicious or unusual activity (a tip), causing the AI to subsequently cue other satellites in the constellation to pass over and collect high-resolution imagery of the point of interest.

 Autonomous operations off-world currently depend on advanced AI/ML for accurate spacecraft flight, deployment and completion of mission objectives. Spacecraft platforms operating in xGEO/interplanetary space, like Intuitive Machines' Nova -C lunar lander, are dependent on autonomy and computer vision to complete orbital maneuvering and entry, descent and landing (EDL) operations. LUNR's scaled up Nova -D lander, built upon the proven success of Nova-C, will use an array of sensors including a flash LIDAR, LIDAR Doppler velocimeter and laser altimeter to inform the vehicle's AI system of the lunar surface's terrain at the landing site, facilitating a safe touchdown. Due to

the speed of light, the communication delay between the Earth and the Moon is 1.3 seconds, and ~7 minutes on Mars. Lunar landings at the South Pole also do not have a direct line of communication with Earth. As such, remotely piloting most interplanetary spacecraft from Earth is simply not feasible, and AI is necessary to operate the spacecraft to a soft landing.

 The US National Airspace System is planning to deploy AI following the appropriation of $12.5B by Congress to upgrade and automate the US air traffic control system's networks. The current ATC system is supported by technology from the 1960s and stands to be a beneficiary of predictive AI deployment to improve route planning and air traffic management. The global shortage of air traffic control (ATC) personnel has led companies like Archer, Palantir and Surf Air Mobility to develop their own air traffic management solutions for operating in very low level (VLL) airspace below 5,000 ft AGL. AI will be utilized predominantly within the 'Automation Systems' component of the 'Brand New Air Traffic Control System' initiative to reduce the cognitive load on limite d numbers of ATC personnel to support higher volumes of traffic in the NAS, which is expected come with the emergence of advanced air mobility (AAM). We believe the ArcherPalantir collaboration to modernize ATC systems and introduce aircraft autonomy netw orks is well positioned to win a contract

for the 'Automation Programs' segment of the broader project.  Autonomous flight for eVTOL and CTOL aircraft is technically feasible today but will likely not be a factor until next decade. Several of the eVTOL companies, including Archer Aviation and Joby Aviation, initiated their flight test campaigns by remotely/autonomously flying their aircraft before allowing pilots to step onboard. Vertical Aerospace alternatively elected to deploy piloted flight tests from the outset of their development program. Joby in particular has pushed the envelope of autonomous aircraft capabilities following the acquisition of Xwing to obtain its Superpilot autonomous flight technology in June 2024. In September 2025, Joby deployed its Superpilot AI technology onto a Cessna Caravan that registered over 7,000 miles of autonomous operations over 40 flight hours. The company has stated its intent to equip future generations of its electrified passenger aircraft with autonomous capabilities, although its first certified

S4 eVTOL will be piloted. While eVTOL manufacturers continue to develop and test the technology for the future, we believe that near-term approval of autonomous aircraft is unlikely. All eVTOL designs currently undergoing certification are doing so with cockpit flight controls and at least one pilot onboard, per the requirement of aviation regulators (FAA, EASA, CAA, ANAC, etc.). Moreover, The Airline Pilots Association has already signaled opposition to permitting autonomous passenger aircraft, likely creating additional roadblocks within Congress (which ultimately controls FAA funding and statutes). While many drones flying beyond visual line of sight today conduct missions autonomously in government applications, we expect autonomous passenger air vehicles to remain out of reach until the mid-2030s at the earliest.

 Looking ahead: K ey predictions regarding AI's impact on the Aerospace & Defense Industry  Future wars will largely be fought by AI-powered drones with both teaming and swarming capabilities. We believe the Ukraine-Russia War merely reflects the tip of the iceberg in terms of how prevalent drones will become on the modern battlefield. In the future, we envision all fighter jet pilots will take to the skies with a team of at least two CCAs and e ach 'loyal wingman' will be able to deploy one -way attack drones of its own, as reflected by recent mothership tests by AeroVironment, Kratos and General Atomics that launched Switchblade loitering munitions from a Group 5 Reaper UAS and a Valkyrie.

 Spacecraft will be capable of carrying out complete exploration missions on other worlds without direct human input. While NASA's Curiosity and Perseverance rovers on Mars depend heavily on commands from Earth today, future spacecraft, like those built by Intuitive Machines and Redwire, will be capable of landing on challenging terrain, roving across the surface of a celestial body, conducting experiments, and prospecting for valuable resources like rareEarth elements (REEs) and water ice all on their own without being managed by an operator on the ground. This will be further enabled by the ability of generative AI to write its own code and pair it with in-space manufacturing, which could allow a robotic explorer to build mission-specific probes onsite to explore desolate places like the hydrocarbon and subsurface oceans on Europa, Titan or Enceladus.

 Eventually, air travel will become autonomous. The global pilot shortage shows no signs of easing, and growing demand for air travel (combined with reduced costs vs. using human pilots) will necessitate more air traffic volume. While passengers will have to become comfortable with flying on an autonomous eVTOL or commercial airplane for urban, regional and long-haul trips, we believe AI will eventually reach a point where it can navigate conditions like weather, airport traffic and mechanical failures better than a human can.

Source: BlackSky Technology

100 m Wind Speed and MSLP Cycle Time: 2025-03-27 12.00 UTC Valid Time: 2025-04-03 12.00 UTC Source: Spire Global

Source: Archer Aviation

Source: Redwire Figure 61: Ranking our covered companies across 7 different AI dimensions suggests that AVAV, KTOS, BKSY, LUNR, RDW, SPIR and DRS lead in AI

Canada has played a foundational role in the research and development of current Artificial Intelligence technology, including methods used today to train large language models, but has struggled to monetize its contribution. In 2017, Canada became the first country to establish a national AI plan, the Pan-Canadian Artificial Intelligence Strategy. Canada has three successful institutes for coordinating university research, 1) Amii in Edmonton, 2) Mila in Montreal, and 3) the Vector Institute in Toronto to catalyze the creation of AI startups. Under the new leadership of Prime Minister Mark Carney, Canada has begun to define a sovereign AI strategy which aims to deploy ~C$2B on new programs to provide affordable, cutting-edge compute infrastructure supporting global competitiveness.

Early research pedigree is Canada's main strength. Dr. Geoffrey Hinton was an early proponent of neural networks (a precursor to the transformer) at the University of Toronto. Until sufficient computing was available, neural nets were broadly dismissed by the mainstream of AI. Geoffrey Hinton was also a co-inventor of the backpropagation algorithm which is a fundamental method used to train neural networks. The potential of neural nets became evident in 2012 at the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) where AlexNet (the name of their neuralnet) was able to vastly outperform other tools on the categorization of photos. AlexNet was trained using two NVIDIA GTX 580 GPU (now ~$200 on eBay). This event Source: Canaccord Genuity estimates, Company Reports

changed the way neural nets were viewed. AlexNet was built by Ilya Sutskever, later the co-founder of OpenAI, and Alex Krizhevsky who were students of Geoffery Hinton at University of Toronto. Geoffery Hinton joined Google Brain in 2013 after he, Alex and Ilya sold their company DNNresearch to Google. For his contributions, Geoffery Hinton won the 2018 Turing award and the 2024 Nobel Prize in Physics. At the University of Alberta, Richard Sutton developed reinforcement learning with Andrew Barto. He won the Turing Award in 2024 for his work in this field.

(2024): He was a corecipient of the A.M. Turing Award (often called the "Nobel Prize in Computing") for his foundational work on reinforcement learning and a founder of Google DeepMind Alberta in 2017. There are numerous other key individuals who contributed to the early development of modern AI tools from Canadian research organizations such as Yoshua Bengio (element AI acquired by ServiceNOW), Geordie Rose (D-Wave), Raquel Uratson (founder of Waabi and former head of AI at Uber) and many more In the application of the technology, Canada has been slower, largely due to the lack of compute infrastructure; Canada ranks last amongst G7 countries according to a 2024 report by The Dais , Toronto Metropolitan University's public policy think tank. There are notable exceptions. Toronto-based Cohere is an early player in the development of large language models and is the best funded Canadian AI startup with US$1.5B raised and a valuation of ~$7B valuation since its founding in 2019.

Formed by former ATI Radion GPU designers in 2016, Tenstorrent, is another Canadian success story, but one which relocated to California to access funding (and compute). Amongst public companies, Celestica (CLS-T, CLS-N | BUY) has emerged as a leading player in both AI compute and networking infrastructure as a key vendor to Google. In the application layer, amongst public companies, we highlight Shopify (SHOP-Q, SHOP-T) which has been an early adopter of AI and more recently has been at the center of the shift to Agentic Commerce. As well, we highlight Coveo (CVO-T) as an enabler of both agentic AI and machine learning for enterprise applications and a partner supporting the go-to-market AI efforts of larger software players like SAP, Shopify and Salesforce. Figure 62: Ranking our covered companies across 7 different AI dimensions Source: Company Reports, Canaccord Genuity estimates

Biotechnology companies have utilized AI-like tools for drug development for some time now, but development timelines could accelerate as new methods are employed. We see potential for AI to automate and integrate multiple types of discovery results, especially within vivo testing, allowing for faster lead generation and evaluation. Small molecule development could see the largest impact, as the modality is well understood, and less complex than biologic or cellular therapies.

The initial hope for AI in the biotechnology sector was to improve drug discovery in an effort to cut down the time and capital needed to get a drug successfully across the finish line. To date, that hasn't quite panned outthere are only a few AI-discovered candidates in late-stage clinical trials and none yet approved. The focus has since shifted to collecting larger data sets in order to build more accurate drug discovery models which we're hopeful will yield more success. For example, LLY recently launc hed its TuneLab platform, an AI/ML platform that 'provides biotech companies access to drug discovery models trained on years of Lilly's research data' which will also be accessible to smaller biotechnology companies.

Where AI has started to see success in biotech thus far is in the regulatory setting by accelerating filings. According to a McKinsey report published in August, some leading pharma companies are now filing regulatory submissions up to 3x faster than the industry average in 2020 with the help of AI. And in June, the FDA launched Elsa, a gen AI tool designed to 'help employeesfrom scientific reviewers to investigators -work more efficiently.' AI can help speed up drug filings to accelerate the regulatory approval process. Along these lines, AI could be utilized in generating information that could support regulatory filings, and the FDA also recently issued draft guidelines on this topic which outlines a risk-based credibility framework for using AI models throughout the drug product lifecycle (nonclinical, clinical, postmarketing and manufacturing).

The Med-Tech sector is increasingly relying on AI to not only enhance operational efficiency but provide a foundation for products reshaping healthcare. Based on our current coverage, it's clear that most companies are integrating AI in some capacity, but more so with products focused on diagnostics. We believe the next wave of successful Med-Tech innovators will be those that harness AI to fully power their products or significantly accelerate the speed, efficiency, and iterative development required for sustained commercial success. In musculoskeletal and surgical care, we expect AI to fundamentally reshape how procedures are planned, performed, and monitored. Data-driven decision support should reduce variability in outcomes over time, improve surgical precision, and accelerate the adoption of robotics and navigation systems. We expect AI to expand from being a technology enabler to a core differentiator, influencing everything from implant design to post-op rehabilitation to surgeon and healthcare staff workflows. Some specific use cases include:

 AI as the Foundation of Technology for companies focused on diagnostics (Ceribell, Dexcom, HeartFlow, & iRhythm Technologies): Companies like Ceribell (CBLL), Dexcom (DXCM), HeartFlow (HTFL), and iRhythm Technologies (IRTC) exemplify how AI can serve as the backbone of a product. These firms are leveraging AI to develop diagnostic solutions to enhance existing treatment paradigms. In most cases, they are integrating medical device hardware with AIpowered software to elevate the standard of care.

 Harnessing AI diagnostics to enhance diabetes management (Insulet and Tandem): AI is also driving innovation in the diabetes pump space, particularly among companies like Insulet (PODD) and Tandem (TNDM). By utilizing continuous glucose monitoring (CGM) data, these devices use AI to optimize and automate the timing and dosage of insulin delivery, helping patients maintain blood glucose levels within target ranges. Improved time-in-range has significant health benefits for diabetics, and both companies continue to refine their algorithms to enhance glycemic control and address new patient populations.

 Boosting Efficiency and Iteration (Penumbra): Penumbra (PEN) showcases how AI can improve product efficiency, efficacy, and the pace of iterative development. Its Computer-Assisted Vacuum Thrombectomy (CAVT) technology automates the detection and removal of blood clots. By continuously enhancing its underlying algorithms, Penumbra accelerates product cycles and has carved out a competitive edge in the thrombectomy market.

 Ongoing, active adoption of AI across the portfolio poised to enable crossdivision synergies (Stryker): Stryker has begun to leverage AI in many different aspects, including in its Blueprint shoulder pre-planning technology in its orthopedics division and its workflow simplification tools in its surgical division. Stryker sees its acquisition of care.ai as a welcome addition to its healthcare IT offering as it provides AI-assisted virtual care workflows and smart room technology solutions. We view AI here as advancing Stryker's ability to be a one -stop-shop for hospitals with the latest & greatest from a connected workflow solutions perspective, building off its Vocera acquisition in 2022. With many areas of opportunity to leverage AI in its portfolio, Stryker has recently hired a Chief Digital Information Officer with experience in generative AI to provide infrastructure to help divisions leverage specific capabilities.

-  Utilizing AI to improve orthopedic surgical reproducibility and outcomes (the strategics, Alphatec): Whether at the startup level or as one of the larger players in orthopedics, it's clear that better technology to drive better outcomes will continue to be an area of significant investment/funding. We see the implementation of AI as a natural progression of enabling technology capabilities. For example, Zimmer Biomet (ZBH) acquired OrthoGrid and its Hip AI surgical assistance platform, which provides AI-powered intra-op navigation tools for hip surgeons. Of course, the large-cap ortho players are looking at ways to integrate AI across their businesses, as big data is the name of the game when generating meaningful insights from these AI solutions (and these companies have a lot of it). We also see AI as having particular importance in areas of orthopedics where surgeries are more complex and current revision rates are relatively high, such as in deformity spine and foot & ankle surgery. On these fronts, smaller companies are getting in on the action: Alphatec is

innovating in deformity spine with its weight-bearing imaging EOS machine and with Insight, its end-to-end, cloudbased spine surgery software platform combining EOS imaging and AI capabilities. Paragon 28, now a part of Zimmer Biomet, introduced its first Smart28 software solution module last year utilizing 3D analytics and AI algorithms to enhance pre-op planning and surgical accuracy. Indeed, we see AI as being an integral part of the surgical solutions landscape in ortho going forward.

Source: Canaccord Genuity estimates, Company reports Figure 64: ZBH and SYK lead in AI among companies specializing in musculoskeletal and surgical care Source: Canaccord Genuity estimates, Company reports

The availability of large libraries of molecular data for each individual patient is creating exciting opportunities for research in the diagnosis, treatment, and early detection of disease such as cancer, especially when paired with a patient's clinical data. AI can be used to mine these large volumes of data to address complex biological questions and has the potential to deliver new insights and bring precision medicine into mainstream clinical care. Further, generative AI can help make laboratory tests more accurate, tailored, and personal. Treatments can be personalized by connecting laboratory results to a patient's own clinical data. The drugs recommended, the clinical trials explored, the care pathways evaluated, the adverse events considered, all have the potential to be refined and enhanced when test results are connected to a patient's personal profile, enabling the right patient to be routed to the right therapy at the right time. Some examples of use cases include:

 Address biomarker testing/care gaps and identify patients earlier in their disease progression: Tempus AI aims to unlock the true power of precision medicine by creating Intelligent Diagnostics through the practical application of artificial intelligence in healthcare. The company's primary AI application product is currently 'Next,' an AI platform that leverages machine learning to apply an 'intelligent layer' onto routinely generated data to proactively identify and minimize care gaps for oncology and cardiology patients. As this product gains adoption, Tempus intends to leverage large language models, generative AI algorithms, and the company's extensive database of de -identified data to develop algorithmic diagnostics designed to identify these patients earlier in their disease progression, when treatments are most effective.

 Advance precision medicine and address diagnostic challenges: Guardant Health has multiple partnerships to integrate AI with its precision oncology initiatives. The company has partnered with Meaningful Insights Biotech Analytics (MiBA) to optimize the use of biomarker testing and data analytics to advance precision medicine in patient care throughout the MiBA Network. Guardant also announced a collaboration with Viz.ai (a leader in AI-powered disease detection and intelligent care coordination) to address challenges in lung cancer care. The collaboration aims to help oncologists diagnose lung cancer earlier and make more informed treatment decisions to improve patient outcomes, reflecting the companies' shared commitment to leveraging technology to close critical gaps in cancer care and streamline the patient journey. In 2023, the company announced Guardant Galaxy, a suite of

advanced analytical technologies developed internally and through outside partnerships to enhance the performance and clinical utility of Guardant Health's portfolio of cancer tests and to power the next generation of biomarker and drug discovery. The first application in the Guardant Galaxy suite is an AI-powered scoring algorithm for the enhanced Guardant360 TissueNext PD-L1 test, which improved detection of the cancer biomarker by more than 20% compared to manual pathologist interpretation in the most challenging non-small cell lung cancer (NSCLC) cases.

 Generate foundation models to predict response to and support development of therapies: Natera recently announced the launch of its proprietary AI foundation model platform. These models and applications, which were developed in-house, are designed to drive innovation across therapeutic development, from early target discovery to real-time clinical decision support. The platform features a modular, multimodal architecture composed of three integrated layers (data foundation layer, core model layer, application layer). The application layer includes a digital patient simulator, real-time trial matching and an advanced algorithm that predicts individual immunotherapy responses based on tumor genomics and neoantigen presentation. Illumina's leading sequencing technology (as well as its menu of DRAGEN-powered multiomics offerings, genomics AI tools, and Illumina Connected Analytics platform) has streamlined genomic data generation and analysis.

 Enable analysis and interpretation of multiomics data and improve diagnostic yield: Illumina has invested in AI for genomic interpretation, developing the leading SpliceAI, PrimateAI-3D, and Emedgene xAI algorithms. In January 2025, Illumina announced is collaborating with NVIDIA to advance technology platforms for the analysis and interpretation of multiomic data, accelerating progress in clinical research, genomics AI development, and drug discovery. Illumina will look to expand its customer offerings with models developed by the NVIDIA Biology Foundation Model Research Team and partners. Customers will also be able to leverage these models with their own proprietary datasets to improve the performance for biologically relevant tasks of interest, such as cell state or gene transcription prediction. PromoterAI is the latest addition to Illumina's AI and software portfolio. In 2019, the Illumina Artificial Intelligence Lab released SpliceAI, a deep learning tool for interpreting noncoding cryptic splice mutations. In 2023, Illumina released PrimateAI-3D, which predicts the pathogenicity of protein-coding variants based on evolutionary conservation

and protein structure. A recent study demonstrates that when used together, Illumina's AI classification prediction tools (PromoterAI, PrimateAI-3D, and SpliceAI) effectively double the diagnostic yield compared to using protein-truncating variants alone.  Develop/identify differentiated molecular signatures: Caris Life Sciences' tissue-based profiling solution for therapy selection, MI Profile, can also include proprietary clinical molecular signatures, GPSai and FOLFIRSTai, which were developed by training and clinically validating AI/ML algorithms with the c ompany's extensive multi -modal clinico-genomic datasets. These molecular signatures (offered as laboratory developed tests) provide clinical

utility for molecular diagnosis of cancer and prediction of patient response to treatment. The GPSai signature is a molecular disease classifier that utilizes multiple deep neural networks and hundreds of thousands of molecular features to predict a histologic diagnosis and tumor origin directly from the DNA and RNA sequencing data. The FOLFIRSTai signature is Caris' first clinically validated, AI-powered molecular predictor of efficacy of oxaliplatinbased chemotherapy combined with bevacizumab in patients with metastatic colorectal cancer (mCRC). Figure 65: Ranking our covered companies across 7 different AI dimensions suggests that GH, GRAL, RGEN, and TXG lead in AI Source: Canaccord Genuity estimates, Company reports

GH has further expanded its use of AI since the last CG update. TXG is much more exposed to AI relative the last CG update -since that time, AI has become critical to enable large projects that utilize TXG's single -cell analysis technology.

AI is making its mark in healthcare with initial use cases focused on internal efficiencies and products driving improved administrative workflow such as AI scribing, scheduling, and summarizing patient chart tools. Over the past year, companies have begun to branch out into patient-facing AI use cases, often with the aim of driving patient engagement such as nutrition bots and generating personalized health content. More recently, there has been a push toward more healthcare provider use cases such as clinical reference tools that assist in actual patient care. We expect AI adoption to continue to be slower and more measured than other industries considering the greater risk to patient care, but the power of the technology is continuing to gather momentum, garnering significant investment and greater adoption.

 AI-driven products driving efficiency in provider workflows (Waystar, Phreesia, Doximity): Healthcare technology companies such as Doximity (DOCS), Waystar (WAY), and Phreesia (PHR) are leveraging AI within their revenue cycle and workflow products to healthcare providers to drive efficiency and accuracy as well as reduce administrative burden. Specific use cases include ambient scribing (DOCS), drafting appeals letters (DOCS & WAY), insurance verification (PHR & WAY), and intelligent call management (PHR) to name a few.

 Leveraging AI to boost productivity in care delivery and improve patient engagement (Hinge Health, Omada Health, Talkspace) : Digital health companies are using AI internally to boost the productivity of their care teams. Virtual care providers such as Hinge Health (HNGE), Omada Health (OMDA), and Talkspace (TALK) are leveraging AI to summarize past patient interaction and intelligently prioritize patients to engage for optimal value. Further, companies are also utilizing AI solutions, under the supervision of providers, to engage patients between visits and supplement provider interaction, namely Omada's OmadaSpark and Talkspace's AI -generated podcasts.  AI moving toward use cases assisting in patient diagnoses and care (Doximity) : Companies are beginning to create tools to support clinicians in the provision of patient care. Doximity (DOCS) announced its acquisition of Pathway in August, adding clinical reference functionality to its AI platform with the promise of providing evidence-based clinical reference for physicians at the point of care.

AI is rapidly reshaping the sector, with both direct and indirect impacts across autonomy, power, and energy. Autonomous driving is at the forefront, where companies like Aurora, Tesla, Mobileye, and Rivian are embedding AI into their systems, and increasing the need for next-generation sensor manufacturers such as Aeva and Arbe. For Uber and Lyft, the rise of autonomy presents a fine line, either a major growth opportunity if they can integrate AI effectively, or a disruptive threat if competitors like Tesla and Waymo scale their platforms and consumers no longer need their services. Beyond transportation, energy and battery companies including Ameresco, Enovix, Fluence, Generac, and NuScale stand to benefit from the surge in power demand driven by AI's exp ansion, particularly as data centers proliferate. At the grid level, meeting this new demand will require significant growth in power output, positioning many of our coverage companies to capture increased demand for their products and services.

 Autonomous driving & related rideshare businesses: We sit at the inflection point of autonomy. Companies like Aurora, Tesla, and Mobileye are expanding autonomy's reach both in the US and globally. Additional beneficiaries include Aeva and Arbe, while Uber and Lyft may face disruptive threats.

 Aurora: After decades of research and backed by 1,450+ issued/pending patents, Aurora's leadership team developed the compound AI , or hybrid, system which includes a tightly integrated collection of advanced self-driving software, hardware, and maps/other data services. The system's hardware sensor suite includes lidar, radar, and cameras, and is powered by a vehicle agnostic, high-performance computer that synthesizes the sensor data and controls the vehicle. The software behind the Aurora Driver fuses both AI/machine learning and fundamental engineering. With machine learning, the system can develop the nuances of a human driver, while with engineered systems, the platform can bring to bear simple rules-based driving policies. Aurora's ultimate goal is to deploy class 8 autonomous trucks at scale, operating endpoint-to-endpoint freight logistics in all driving conditions. On April 27, Aurora commenced driverless operations on the company's

I-45 Dallas-Houston launch lane. At the end of 2Q25, the company had completed >20,000 miles without a driver. Importantly, there have been zero instances of safety rider intervention. In June, Aurora initiated lane expansion by opening the company's Phoenix terminal, which supports trips from El Paso, TX, to Phoenix, AZ. In total, Aurora has five terminals, supportive of initial lane launches, one in Dallas, one in Houston, one in Fort Worth, one in El Paso and one in Phoenix. Also in June, Aurora completed the validation and commenced nighttime driverless operations.

 Tesla: As of the 2Q earnings conference call, Mr. Musk shared the ambition of making Tesla ride-hailing services available to half of the U.S. population by year-end. Tesla is working to expand the Austin, TX, service area and expects imminent service in the Bay Area, Nevada, Arizona, Florida and a number of other locations, pending regulatory approvals. On June 22, Tesla officially launched a small fleet of self-driving robotaxis; the Model Y robotaxis chauffeured invite-only riders around South Congress, an Austin, TX, neighborhood. While the majority of rides were smooth, there were several reported issues, including entering the wrong lane, dropping passengers off in the middle of multi-lane roads, ghost-braking and speeding. Management believes successful deployment in Austin will enable additional deployments with marginal investment. According to management, "in June, we launched our Robotaxi service in the first city, Austin, with a safety rider. We will further improve and expand the service (more vehicles covering a

larger area, eventually without a safety rider) while testing in other U.S. cities in anticipation of additional launches. Our efforts to refine the Robotaxi offering in Austin are not location-specific and will allow us to scale to other cities quickly with marginal investment." Tesla expects to launch FSD in select European countries and restart China deployments in the near term. Following the Robotaxi launch, on June 28, Tesla officially autonomously delivered its first vehicle. According to the company's post, " this Tesla drove itself from Gigafactory Texas to its new owner's home ~30min away -crossing parking lots, highways & the city to reach its new owner. "

 Mobileye: In June, Mobileye announced an imaging radar win with a 'leading global automaker.' Beginning in 2028, Mobileye's technology will be integrated into the unnamed OEM's sensor suite, driving the redundancy required to deliver SAE Level 3 autonomous driving up to 75 mph. Mobileye plans to leverage imaging radar over LiDAR as management expects sensor innovation to drive down the degree of autonomous system redundancy and associated costs. Mobileye's partnership with VW is expected to drive Mobileye European robotaxi penetration while its Lyft partnership is expected to deploy Mobileye Drive-enabled Texas robotaxis in 2026.

 Rivian: The company has been, and continues to ramp, autonomy efforts; management expects hands-free eyesoff driving will 'be available essentially everywhere,' and continues to expect 'hands -free, eyesoff' driving in 2026. The R1 Gen2 perception stack continues to improve, now including higher quality cameras and greater compute power. Rivian plans to use an end-to-end approach, integrating cameras and five radar devices. Management used the Gen2 R1 platform as an autonomy reset: ' we call it [the] Rivian Autonomy Platform, and that's 55 megapixels of cameras around the vehicle. We have 4 corner radars and [a] front engine radar for [a] total [of] 5 radar. Those feed into a much higher compute platform, about 10x the compute levels... And we're using an end-to-end approach where the Rivian owned camera and perception stacks feed into our vehicle rather than identify unique events training our model.' High performance cameras -alongside high

quality imaging radar -will help Rivian expedite its end-to-end training model.  Battery & Storage: Battery- and energy-related companies including Fluence, Enovix, and Generac are direct beneficiaries of the increase in power consumption from AI applications.  Energy: Beneficiaries include Ameresco, NuScale, ASP Isotopes, FuelCell and Plug. Ameresco works in the energy efficiency space and develops and manages energy assets, which are critical for increasing energy producing assets. Similarly, NuScale develops nuclear reactors while FuelCell and Plug operate in the hydrogen and fuel cell ecosystem, all of which could work with AI customers and are helping to power data centers. Lastly ASP Isotopes is looking to enrich isotopes critical for both the nuclear energy and quantum computing spaces. -  Rare Earth Magnets: MP Materials and USA Rare Earth are also expected to be beneficiaries of the growth in AI. Rare earth magnets are critical for applications including robots, clean energy systems and electric vehicles.

Figure 67: Ranking our covered companies across 7 different AI dimensions suggests that AUR, TSLA, MBLY and RIVN lead in AI Source: Canaccord Genuity estimates, Company reports

AI is impacting the consumer in their querying and buying behavior in several ways. Many consumers searching on Google no longer click on search results for answers to their questions but instead use the AI-generated Google responses to shortcut their search. This results in AI having control over the content that is most likely to be read and activated on, and the actual search results have significantly lost their value. This changes companies' approach to SEO and requires additional focus on GEO and AEO. Consumers are also now leveraging the AI summary in e-commerce platforms to understand the content of the reviews, rather than wading through and reading the top and bottom reviews. Therefore, companies need to be even more diligent about understanding the content of reviews, ensuring 4- and 5-star ratings, and continuing to drive additional ratings and reviews whenever and wherever possible. Finally, AI has been fueling algorithms for social platforms. It is not only the creator but also the curator. This should have a significant impact on the requirement for hyperpersonalization, automated media selection, and potential misinformation.

AI is changing how we search, shop, consume content, and learn every day. While we don't yet know exactly where this will take us in the medium - and long-term, it is already changing behavior, creating efficiencies in processes and data analysis, and helping humans to consider and consume even more content than ever before. While we need to be incredibly thoughtful about how we use AI in the business environment, we cannot ignore its potential. However, we do not believe AI will take over all human work, particularly in the creative space, and cannot replace personal face-to-face relationships with investors, suppliers, vendors, etc. Still, we need to evolve and learn how to leverage AI, test its potential, and learn from the opportunities that it presents.

Recall, as we discussed in January 2024, COOK turned to AWS as its new IoT provider for its line of Wi-Fi enabled grills, with plans for further implementation of

AI. Amazon Web Services (AWS) reported how its IoT Competency Partner OST helped COOK migrate 111k devices and 700k mobile users to AWS IoT Core in just three months, after COOK's original IoT vendor decided to sunset its platform. After successfully switching to AWS, COOK doubled the number of IoT connected grills to 300k in just 18 months. COOK had initially targeted $6 per device for the cost of replatforming, but by the end of the migration that cost had been reduced to $0.50 per device. Consumer Goods Technology also reported that COOK has become an early adopter for several new genAI capabilities in Amazon Connect, AWS's cloud contact center. Using Amazon Connect Contact Lens, employees can avoid reading extensive call transcripts or listening to full recordings and instead use summarized important information. Through machine learning to dig deeper into its IoT data, COOK is developing predictive models that can signify part replacements and ultimately boost sales. Better insights around grill usage by region and consumer will help the company

better predict wood pellet sales, which is a major revenue source. COOK intended to use its IoT data to personalize its customer experience and recommend new product uses and recipes through prescriptive AI modeling.

In August, AWS reported how Traeger grills have cut per-device cloud costs by 50 %. Traeger utilized Amazon DynamoDB, AWS Lambda, Amazon Elastic Container Service (ECS), and other AWS services that transformed its IoT platform 'into a model of costefficient reliability.' Traeger optimized its cloud architecture whilst upholding a 99.99 percent uptime that users depend on, even during peak cooking times like Thanksgiving. Regarding Amazon DynamoDB, Traeger shifted from on-demand capacity to dynamic provisioning, which significantly reduced costs while maintaining performance. In all, Traeger saw dramatic decreases across all major AWS services, such as a 71% reduction in DynamoDB costs, a 54% reduction in API Gateway expenses, a 53% reduction in Lambda costs, and a 47% savings in storage costs. Traeger continues to explore machine learning capabilities to provide more personalized cooking experiences while also further optimizing resource usage with predictive scaling. Figure 68: Smoking out costs -Traeger & AWS partner to optimize cloud Source: AWS

EZCORP , the second largest pawn store operator in both the U.S. and LatAm, intends to use AI to contribute to flexible and proactive systems which will increase digitization in its historically physical business. The company envisions using AI in the short term for assisted content creation, enhanced employee service, business intelligence, pricing redesign, and e-commerce. In the mid- to long-term, AI could be used to create frictionless store processes, for fraud detection and prevention, product management, internal and external customer service, omnichannel customer experience, and robotic processing automation with embedded AI. Management has also emphasized that AI should be managed carefully, cognizant of the quality of training data and models used, data privacy, regulatory compliance, and sufficient human oversight. Current use cases include the use of Entrupy, AIpowered software, to authenticate luxury handbags.

Secure inventory; protect supply chains; and add trust to transactions at retail and resale Source: Company Website Industry leader FirstCash uses AI-like proprietary algorithms to determine collateral value, loan-to-value (LTV) ratios, and retail pricing, which we find quite similar to EZPW's POS system. According to FCFS, pawnbrokers can use the model number of a product to retrieve the last ten transactions done within the store for that product, and then figure out what to lend based on those figures as well as customer history. Similarly, EZPW owns a portion of Rich Data Corporation (RDC), a Singaporebased software-as-a-service company that uses global financial services expertise, advanced artificial intelligence, and non-traditional data to form its next generation credit scoring and decisioning platform. As we wrote in our initiation, EZPW's proprietary point-of-sale system, POS2, also simplifies the customer

qualification and loan valuation process for pawnbrokers with a cost-effective, flexible decision engine to improve lending guidance and product pricing. EZPW's system provides the retail price for the item as well as the recommended loan range based on customer history.

Hillman's field sales & service team visits customer stores every day. During the early 1990s, the company developed its National Field Service Group, which today includes over 1,200 field service and sales representatives, to manage the complex assortment of HLMN products on its customers' shelves. Over the next three decades the company continued to win new business, expanding from traditional hardware stores to big box and home improvement retailers, and into adjacent product categories through multiple strategic acquisitions. HLMN's role varies by customer and ranges from managing the aisle, organizing and cleaning displays, managing inventory, and ordering products. The team is a key competitive differentiator.

HLMN's customers rely on its long -tenured sales and service team, which experiences low turnover. The team consists of four groups: traditional hardware, big box retail, Canadian retail, and robotic kiosk technologies (RDS) techs. When a consumer goes to any store as a DIYer or a pro, HLMN products are in drawers or on pegboards because of this team, which for the past 29 years has worked in its customers' stores regularly. With an average rep tenure of over 11 years and low turnover, it would seem nearly impossible for a competitor to replicate. The team defies the odds in retail.

Hillman believes its 1,200 folks in the field and the face-to-face sales and service will continue to drive Hillman in the future but is starting to evaluate how AI can make those 1,200 folks more efficient, particularly when it comes to category management. Hillman can leverage AI to ensure it has the right products in the right place at the right time for customers. This is particularly valuable with smaller customers who do not have the resources the big box retailers do. Hillman believes there is a lot of powerful data considering its 112,000 SKUs, 29,000 retail ship-to locations, and frequent SKU-level reporting from its customers, so AI can help the company win. Additionally, it is evaluating how to leverage AI to improve operations in its distribution centers, logistics and throughout the supply chain. Hillman is partnering with an AI company today and expects that partnership to deepen over time.

Middleby shows its commitment to innovation and AI through its L2F acquisition and products such as the FryBot , an automated fryer that was installed in test locations in 2023 and was in full force in August 2024, with multiple operational and on display across the U.S. The FryBot utilizes robotic automation to create a safer, more efficient kitchen. Benefits include: reduced labor cost of $60,000-$75,000+ due to automation; decreased food waste from overuse and bad cooks up to $10,000+; increased safety by automating dangerous jobs, considering the average cost for fryer burns of $5,928; reduced oil waste of up to $5,000 due to automated SOPs; reduced employee turnover; and saving on-boarding and training cost, resulting in savings of $6,000+. FryBot list prices can range from $235k to $365k depending on the SKU. The actual price is usually ~20% or more off the list price. Figure 70: The FryBot utilizes robotic automation to create a safer, more efficient kitchen Source: Company Website

As we wrote in March, in MIDD's Embedded, Digital, and Robotic Automation (a future market TAM) segment, products consist of the PizzaBot 2.0, the Carter Hoffmann PUC, the FryBot 3.0, and the Taylor Next-Gen Grill. The PizzaBot and Taylor Grill both have embedded automation, while the PUC cabinet is digital and the FryBot is robotic. Figure 71: In Embedded, Digital, and Robotic Automation (a future market TAM), products consist of the PizzaBot 2.0, the Carter Hoffmann PUC, the FryBot 3.0, and the Taylor Next-Gen Grill Source: Company Presentation

 Content Creation : Newell partnered with Adobe to rebuild its content supply chain using Adobe Firefly, Workfront, Experience Manager, and Express. This enabled teams to produce 5x more content with greater speed and consistency. For example, Paper Mate packaging production was accelerated by 75%, and Oster social content creation time was reduced by 33%.  Insights Platform (iHub) : Powered by Stravito, Newell launched 'iHub,' which allows employees to share information globally and fully leverage customized and syndicated data. Employees can search global research using natural language queries like 'tell me what we know about coffee drinkers.' Usage jumped from 30 to over 450 employees, resulting in the incremental value of its innovation pipeline growing 3x as a result.  Synthetic Personas : Using ChatGPT, Newell created AI personas to simulate consumer panels. These personas help test product concepts, packaging, and messaging with high accuracy, especially with limited budgets.

 Innovation Acceleration (InnoGEN ): Newell's InnoGEN framework uses generative AI to increase ideation volume by up to 5x, democratize creativity, and compress development timelines. AI personas assist with critique, copywriting, sustainability, and regulatory review.  Prompt Engineering : Newell hired its first prompt engineer and upskilled teams to use tools like Midjourney for rapid concept visualization, cutting weeks from product development cycles.  Automation & Robotics in Manufacturing : In areas where applicable, the company moved from slow repetitive manual tasks and operations to high-speed automated operations with fewer but higher skilled staff.  Consumer Interactions: Moved from email and phone based to fully agentic AI with written or voice interactions with simplified fast interactions that improve satisfaction.  Customer Orders & Service: From EDI, email and phone orders to full agentic AI for tracking, email and voice and a customer portal into Newell for self-service.

 Faster Innovation : Consumers will benefit from quicker product launches and more tailored offerings, thanks to AI-driven ideation and testing.  Improved Relevance : AI personas simulate consumer behavior, helping ensure products resonate with target audiences, especially younger demographics.  Enhanced Content : AI automates asset creation and localization, allowing Newell to deliver on-brand, channelspecific content that's more engaging and consistent.  Greater Empathy : InnoGEN embeds consumer insights early in the process, enabling Newell to design products that meet real-life needs -from parenting to sustainability.  Trust and transparency: Newell's policy forbids use of AI -exclusive outputs with consumers, but AI enables and accelerates. It augments but doesn't replace human creative process and output. It doesn't distort reality (as in, the company doesn't use AI imagery without proper human intervention).

 Strategically, Newell sees AI as an enabler to accelerate its WTP/HTW choices. AI helps Newell leapfrog legacy systems and tech debt, positioning the company as a future-ready leader in consumer goods.  Operationally, AI has unlocked significant efficiencies: faster speed to market, reduced costs, and expanded capabilities without increasing headcount.  Culturally, it's boosting employee engagement and morale. Teams are energized by learning new skills, contributing to innovation, and seeing tangible impact.  At Newell, AI is not a replacement for human effort but an accelerant. It's helping Newell scale smarter, innovate faster, and connect more deeply with consumers.  Younger generations expect employers to leverage AI and will flow to companies that embrace it, not resist it. Responsible use of AI enhances the employee experience and Newell's employee value proposition.

Last month, we discussed how SN will be relaunching its direct-to-consumer website sharkninja.com, powered by the Salesforce e-commerce platform. This relaunch is expected to be live in North America by Q4, followed by international direct-to-consumer sites in Q1 2026. Recall, in January we discussed how SN was implementing Salesforce's Agentforce and Commerce Cloud to utilize autonomous agents in customer service. This followed SN signing Salesforce to be its new ecommerce partner in November. We concluded that SN does many things very well, but direct-to-consumer and ecommerce are clear areas for potential improvement. We also wrote that we estimate DTC as a percentage of sales has not materially changed since 2023, but viewed this site revamp as a logical first step.

In addition, SN's new Chief Innovation and Technology Officer (CITO) Mr. Mike Harris will focus on unlocking the 'next wave of consumer -first innovation' for SN. He will help SN deliver five-star consumer experiences at scale through the combination of robotics engineering, app and IoT platforms, and global electrical engineering. CEO Mr. Mark Barrocas believes that Mr. Harris' s 'deep expertise and visionary approach will be instrumental in scaling our innovation engine globally and pushing the boundaries o f what our products can do.' Mr. Harris will not only lead global technology teams but also closely collaborate with design, product, marketing, R&D, and operations teams.

YETI utilizes Salesforce's Commerce Cloud Einstein which enables AI to make tailored product suggestions for consumers based on their past purchases, geographic region, and even as specifically as their preferred outdoor activities. As Salesforce explains, YETI has also reduced call center costs and support times by combining customer data in Salesforce's Service Cloud, a system that 'reimagines service with trusted AI.' The two platforms interface with each other, so customer service representatives can not only use data to personalize support but also place and modify orders on behalf of a customer. Looking ahead: Key predictions regarding AI's impact on Consumer

We reiterate our view that power will shift from brands to consumers as consumers gain unprecedented access to AI technologies. We agree with AdAge, that digital first started this power shift, as consumers can utilize search engines, ratings, and reviews for their decision-making process. Social media then brought about influencers and real-time product reviews. AI will create customers who are even more savvy and discerning, and thereby quicker to adopt and abandon brands. With SharkNinja's business model based on five-star reviews, we believe it is the company in our coverage most impacted by AI in the near term.

Source: Canaccord Genuity estimates, Company reports Figure 73: Perfect Corp's AI solutions for skin care Source: Perfect Corp.

The beauty, health, and wellness sector and the general consumer industry continue to utilize the increasing number of AI-powered tools to help drive operational efficiency. These tools have been implemented to help with working capital management, supply chains, improve day-to-day corporate functions, new product research & development, and also can be used to personalize shopper experiences. Other use cases include AI chatbots for customer service. Overall, we believe there are certainly use cases within the beauty, health, and wellness industry and larger contributions from AI tools will likely occur within product development. For beauty brands, these tools could analyze large amounts of data including ingredient data to help with new product development. We believe a similar trend is occurring within Figure 74: Ulta utilizes AI data driven insights to personalize the beauty experience for their guests Source: Ulta Beauty health & wellness companies where these tools can identify molecules to target certain health needs with more efficacy. To a lesser extent, AI tools could also help with inventory management for brands and retailers and a more personalized shopping experience. Here are some specific examples of usage today:

 AI tools can help with personalized shopping experiences: With companies increasingly getting more consumer data through their own site or app, we believe AI tools can help turn these data libraries into actionable offerings including personalizing the consumer shopping experience. This ranges from curating what products and brands consumers see while shopping online to what type of coupons consumers receive. We highlight beauty specialty retailer Ulta, which uses their Ultamate Rewards loyalty program, to gain key insights into their customer interests. Ulta creates data driven insights using AI to help deliver a personalized shopping experience including showcasing brands and products the consumer is likely interested in. This helps drive retention, increased customer satisfaction, and conversion.  Predictive AI helps retailers and brands with inventory: Retailers are continuing to invest more in AI-powered tools to help manage their supply chains and inventory more efficiently. Target uses Inventory Ledger, a system that helps track inventory and consumption trends across stores to reduce out of stocks. Walmart also uses a platform with similar capabilities.

 Product development is sped up with the help of AI: Major beauty and wellness companies continue to invest into AI capabilities to help manage their product library and to also help with product development. Estee Lauder has partnered with Microsoft and uses a tool called Trend Studio to help accelerate product gotomarket. L'Oreal also utilizes an AI tool called Trendspotter that helps detect trends early on. The tool reviews social media and blog chatter and allows L'Oreal to more accurately predict future trends to improve product launches.

 AI helps create hyper personalized skincare, beauty, VMS, and personal care products: We have seen most beauty brands adopt AI, whether it is for shopping online to help consumers try on makeup virtually, or to help consumers visualize what skin care products can do for their skin. Perfect Corp. is a major AI/AR software company that creates tech products for beauty and wellness companies. Oddity is a consumer tech, AI focused platform that owns a number of beauty brands and utilizes their proprietary PowerMatch and SpoiledBrain algorithms to help pair customers with accurate color cosmetic complexions, helping avoid the need to test and shop color cosmetics in-store. Oddity also uses their Computer Vision technology which uses AI technology to analyze skin and hair features to recommend various skincare products. Looking ahead: predictions regarding AIs impact on the Beauty Health, & Wellness Industry Key

-  AI-powered solutions to help with inventory planning and management: We expect more companies in the consumer space, including within beauty, health & wellness, will continue to utilize AI tools to help better predict complex inventory management needs. We believe companies are increasingly using tools that track social media buzz to better help manage SKU demand, distribution across stores, and even personalized promo offerings. These capabilities should help improve working capital efficiency, reduce inventory obsolescence, and potentially reduce promotions.

 AI tools help with personalization: We believe consumers continue to look for personalization across their consumer shopping journey. This includes personalized offers and products. We have seen companies in the beauty, health, and wellness category invest in tools to help with personalized shopping experiences including targeted emails highlighting products they may be interested in, helping personalize ad recommendations to drive better conversion or product and brand discovery, and even personalized promos to help bring customers back to the store or site. Brands and retailers are also using AI tools to help create a personalized beauty or wellness regimen including helping with product matching or creating a personalized product for the consumer. Peloton has been rumored to be planning an integrated AI platform later this year called Peloton Intelligence that will help provide more personalized workouts.

 Beauty and wellness companies using AI to help with product development: We continue to see companies in the beauty, health, and wellness industry utilize AI as a tool to help develop new products. Within beauty, Estee Lauder and L'Oreal have utilized tools to help track consumer sentiment, wants and needs to be able to pivot their product development pipeline to meet consumer demand. Tools can also help quickly review decades of consumer data, surveys, product usage, and clinical trial data and turn the data into actionable ideas. These tools can speed up the go-to-market timeframe to months instead of years. Additionally, within fragrance, we are seeing major fragrance houses such as DSM-Firmenich and Givaudan digitizing their scent portfolio and ingredients into a digital library and utilizing AI tools to help introduce new scents and formulations. Within the health & wellness category, we are seeing brands utilize AI tools to help with molecule discovery. These tools can help reduce guesswork and time to

get a product to market by predicting how different molecules could interact with each other and if they can help target specific health needs.  Retailers and brands using AI for customer service needs: Brands and retailers continue to look for ways to drive efficiency and are implementing AI tools to manage customer service. We have seen AI utilized for online chatbot messaging, which also can lead to multi-lingual support, and help point consumers in the right direction for self-help solutions. We believe if implemented correctly, this could help improve the customer experience and allow customer service representatives to focus on more complex customer service needs.

Source: Canaccord Genuity estimates, Company reports Canaccord Genulty

| Company Logo            | Company Name            | Valuation (SM)   | (SM)    | Headcount   | Product Category                           | Sector                  |
|-------------------------|-------------------------|------------------|---------|-------------|--------------------------------------------|-------------------------|
| TECHNOLOGY              |                         |                  |         |             |                                            |                         |
|                         | Ipassword               | $6,800           | $944    | 2,641       | Security & identity                        | Software Security       |
|                         | 6Sense                  | $5,200           | $516    | 1,582       | SalesTech                                  | Software Applications   |
|                         | Abridge                 | $5,300           | $758    | 389         | Clinical documentation & ambient AI        | Software Applications   |
|                         | Al21 Labs               | $1,400           | $637    | 269         | Foundational Al Model                      | Software Infrastructure |
| AIDA                    | Aida                    | nla              | nla     |             | Al Chatbots                                | Software                |
| Airbyte                 | Airbyte                 | $1,500           | $181    | 142         | Data Integration                           | Software Infrastructure |
|                         | Algolia                 | $2,250           | $334    | 851         | Al applications (search/agentslautomation) | Software Infrastructure |
|                         | AlphaSense              |                  | $1,397  | 2,549       | Market intelligence & enterprise research  | Software Applications   |
| AltaML                  | AltaML                  | nla              | $13     | 128         | Al Application Development                 | Software                |
| ANTHROPICAnthropic      | ANTHROPICAnthropic      | $183,000         | $30,660 | 2,307       | GenAl models & multimodal APIs             | Software Infrastructure |
|                         | Anysphere (Cursor)      | $9,900           | $1,073  | 1,365       | Alengineering tools & frameworks           | Software Infrastructure |
|                         | Apollo.io               | $1,600           | $251    | 700         | Sales Tech                                 | Software Applications   |
| FRCTIC                  | Arctic Wolf             | $4,300           | $899    | 3,199       | Security & identity                        | Software Security       |
|                         |                         |                  | $3      | 219         | Spacecraft Simulation Software             | Space-as-a-Service      |
| @entive                 | Attentive               | $6,970           | $922    | 1,552       | MarTech                                    | Software Applications   |
| AUTOMATION ANYWHERE     | Automation Anywhere     | $6,800           | $1,049  | 2,625       | RPA                                        | Software Infrastructure |
|                         | Axonius                 | $2,600           | $675    | 823         | Security & identity                        | Software Security       |
| B baseten               | Baseten                 | $2,150           | $290    | 114         | Al inference & compute platforms           | Software Infrastructure |
| bloomreach              | Bloomreach              | 200              | $927    | 900         | MarTech                                    | Software Applications   |
| bluej                   | Blue J                  | nla              | $139    | 88          | Al Tax Advisory                            | Software                |
|                         | BrowserStack            | $4,000           | $250    | 1,745       | DevOps & IT ops platforms                  | Software Infrastructure |
|                         | Canva                   | $40,000          | $578    | 13,185      | Design & content creation platforms        | Software Applications   |
| CAIO                    | Cato Networks           | $4,800           | $1,179  | 1,375       | Security & identity                        | Software Security       |
| Chainalysis Chainalysis | Chainalysis Chainalysis | $8,600           | $537    | 803         | Blockchain Data Platform                   | Digital Assets          |
| Chainguard              | Chainguard              | $3,500           | $612    | 554         | Security & identity                        | Software Security       |

| Company Logo          | Company Name          | Valuation (SM)   | (SM)       | Headcount   | Product Category                           | Sector                  |
|-----------------------|-----------------------|------------------|------------|-------------|--------------------------------------------|-------------------------|
| TECHNOLOGY            | TECHNOLOGY            | TECHNOLOGY       | TECHNOLOGY | TECHNOLOGY  | TECHNOLOGY                                 | TECHNOLOGY              |
| characterai           | Character.ai          | $1,000           | $193       | 105         | Gen Al Dialogue Agents                     | Internet                |
|                       | Checkr                | $4,600           | $812       | 1,550       | Background Check Software                  | Software Applications   |
| Clari                 | Clari                 |                  |            | 848         | Sales Tech                                 | Software Applications   |
| CLaROTY               | Claroty               | $2,000           | $640       | 821         | Security & identity                        | Software Security       |
| ClickHouse            | ClickHouse            | $6,350           | $650       | 336         | Data infrastructure                        | Software Infrastructure |
| MI                    | Coactive Al           | $200             | $44        | 64          | Data governance & curation                 | Software Infrastructure |
| Cackrcach Labs        | Cockroach Labs        | $5,478           | $633       | 702         | Distributed SQL Database                   | Software Infrastructure |
| 0e Cohere             | 0e Cohere             | $6,817           | $1,885     | 812         | GenAl models & multimodal APIs             | Software Infrastructure |
| COHESITY              | Cohesity              | $7,000           | $810       | 7,714       | Data infrastructure                        | Software Infrastructure |
| Collibra              | Collibra              | $5,250           | $596       | 1,031       | Data governance & curation                 | Software Infrastructure |
| compss ud             | Compass UOL           | nla              | nla        | 5,000       | Enterprise Al Transformation               | Digital Transformation  |
| Cribl                 | Cribl                 | $3,500           | $715       | 1,039       | Data integration & transformation          | Software Infrastructure |
| Crusoe                | Crusoe                |                  | $1,613     | 768         | Al inference & compute platforms           | Software Infrastructure |
| cyera                 | Cyera                 | $6,000           | $1,305     | 906         | Security & identity                        | Software Security       |
| databricks Databricks | databricks Databricks | $100,000         | $30,297    | 12,291      | Data & Al platforms                        | Software Infrastructure |
| dataiku               | Dataiku               | $3,700           | $847       | 1,529       | Data & Al platforms                        | Software Infrastructure |
| DataRobot             | DataRobot             | $6,300           | $1,048     | 863         | Automated ML                               | Software Infrastructure |
| dbt Labs              | Dbt Labs              | $4,200           | $414       | 874         | Data integration & transformation          | Software Infrastructure |
| d                     | Deep Instinct         |                  | $343       | 215         | Endpoint Security                          | Security Software       |
| DeepL                 | DeepL                 | $2,000           | $400       | 1,560       | AI applications (searchlagentslautomation) | Software Infrastructure |
| 'dialpad              | Dialpad               |                  | $415       | 1,528       | Customer Intelligence                      | Software Applications   |
| Domino                | Domino Data Lab       | $800             | $224       | 207         | MLOps & Data Science                       | Software Infrastructure |
|                       | Eightfold.ai          | $2,100           | $397       | 896         | Recruiting Software                        | Software Applications   |
| ElevenL@bs ElevenLabs | ElevenL@bs ElevenLabs | $3,300           | $281       | 447         | GenAl models & multimodal APIs             | Software Infrastructure |
| exabeam               | Exabeam               | 5248             | $554       | 913         | Intelligence/ SIEM                         | Security Software       |

| Company Logo              | Company Name              | Valuation (SM)   | (SM)       | Headcount   | Product Category                           | Sector                          |
|---------------------------|---------------------------|------------------|------------|-------------|--------------------------------------------|---------------------------------|
| TECHNOLOGY                | TECHNOLOGY                | TECHNOLOGY       | TECHNOLOGY | TECHNOLOGY  | TECHNOLOGY                                 | TECHNOLOGY                      |
|                           | Fireblocks                | $8,000           | $1,038     | 832         | Digital Asset Management                   | Digital Assets                  |
| Fireworks AlFireworks Al  | Fireworks AlFireworks Al  | $552             | $102       | 124         | Al inference & compute platforms           | Software Infrastructure         |
| Fivetran                  | Fivetran                  | $5,600           | $728       | 1,660       | Data integration & transformation          | Software Infrastructure         |
| GENESYS                   | Genesys                   | $21,000          | $2,089     | 8,412       | Contact center (CCaaS) & CX orchestration  | Software Applications           |
|                           | Glean                     | $7,200           | $765       | 1,252       | Al applications (searchlagentslautomation) | Software Infrastructure         |
|                           | Gong                      | $7,250           | $583       | 2,039       | Sales Tech                                 | Software Applications           |
| grammarly                 | Grammarly                 | $13,000          | $1,064     | 1,593       | Gen Al Writing Assistant                   | Internet                        |
|                           | H2O.ai                    | $1,700           | $250       | 317         | Model Development & Management             | Software Infrastructure         |
| harness                   | Harness                   | $3,700           | $370       | 1,473       |                                            | Software Infrastructure         |
|                           | Highspot                  | $3,648           | $660       | 1,124       | SalesTech                                  | Software Applications           |
|                           | Hopper                    | $5,000           | $695       | 1,236       | Al Airfare Prediction                      | Restaurants, Hotels and Leisure |
|                           | Hugging Face              | $4,500           | $396       | 615         | Al engineering tools & frameworks          | Software Infrastructure         |
|                           | Icertis                   |                  | $532       | 2,336       | Legal Contract Management                  | Software Applications           |
| imbue                     | Imbue                     | $1,000           | $246       | 20          | Explainable Al Tools                       | Software Infrastructure         |
| Inflection AI             | Inflection Al             |                  |            | 63          | Gen Al Assistant                           | Software Infrastructure         |
| infogain                  | Infogain                  |                  |            | 6,000       | Al Software Solutions                      | Digital Transformation          |
|                           | Intercom                  | $1,275           | $241       | 1,790       | Customer service & engagement platforms    | Software Applications           |
| E Ironclad                | Ironclad                  | $3,200           | $332       | 702         | Legal Contract Management                  | Software Applications           |
| ITERABLE                  | Iterable                  | $2,101           | $342       | 848         | MarTech                                    | Software Applications           |
| Jasper                    | Jasper                    | 41,500           | $143       | 143         | MarTech                                    | Software Applications           |
| Labelbox                  | Labelbox                  | $810             | $189       | 144         | Data Annotation                            | Software Infrastructure         |
| Lambda                    | Lambda                    | $2,500           | $903       | 597         | Al inference & compute platforms           | Software Infrastructure         |
| LangChain_LangChain       | LangChain_LangChain       | $1,100           | $135       | 125         | Al engineering tools & frameworks          | Software Infrastructure         |
| LaunchDarkly LaunchDarkly | LaunchDarkly LaunchDarkly | $3,000           | $330       | 542         | DevOps & IT ops platforms                  | Software Infrastructure         |
|                           | Lily AI                   | $187             | $52        | 111         | AdtechleCommerce                           | Internet                        |

| Company Logo              | Company Name              | Valuation (SM)   | (SM)    | Headcount   | Product Category                           | Sector                  |
|---------------------------|---------------------------|------------------|---------|-------------|--------------------------------------------|-------------------------|
| TECHNOLOGY                |                           |                  |         |             |                                            |                         |
| LogicMonitor              | LogicMonitor              | $2,400           | $58     | 1,178       | Observability & Monitoring                 | Software Infrastructure |
|                           | Midjourney                | nla              | nla     | 172         | GenAl models & multimodal APIs             | Software Infrastructure |
| MindBrdge                 | MindBridge                | $70              | $82     | 150         | Financial Risk Discovery                   | Software                |
|                           | Mistral AI                | $13,703          | $3,043  | 457         | GenAl models & multimodal APIs             | Software Infrastructure |
| MotherDuck                | Mother Duck               |                  | $100    | 32          | Analytics Processing Platform              | Software Infrastructure |
|                           | Moveworks                 | $2,850           | $308    | 733         | Automated IT Support                       | Software Applications   |
| nnaone                    | NinjaOne                  | $5,000           | $732    | 1,899       | DevOps & IT ops platforms                  | Software Infrastructure |
| OpenAI                    | OpenAl                    | $300,000         | $26,303 | 7,385       | GenAl models & multimodal APIs             | Software Infrastructure |
|                           | Orca Security             | $1,800           | $640    | 473         | Cloud Security                             | Security Software       |
| Outreach                  | Outreach                  | $4,400           | 8538    | 1,281       | Sales Tech                                 | Software Applications   |
| outsystems                | OutSystems                |                  | $805    | 1,998       | Low-code Al Development                    | Software Infrastructure |
| 'pendo                    | Pendo.io                  |                  | $359    | 900         | Digital Product Experience                 | Software Applications   |
| paplexty                  | Perplexity AI             | $20,000          | $1,714  | 250         | Gen Al Search                              | Internet                |
| Pinecone                  | Pinecone                  | $750             | $138    | 134         | Vector Database                            | Software Infrastructure |
|                           | Postman                   | $5,600           | $433    | 3,145       | DevOps & IT ops platforms                  | Software Infrastructure |
|                           | Runway                    | $5,000           | $544    | 120         | Image and video editing                    | Software Applications   |
|                           |                           | $5,000           | $1,138  | 440         | Full Stack Al Platform & Chip              | Software Infrastructure |
| SANCTUARY Al Sanctuary Al | SANCTUARY Al Sanctuary Al | $229             | $119    | 138         | Contract Review                            | Software                |
|                           | Scale AI                  | $29,000          | $15,956 | 5,632       | Data governance & curation                 | Software Infrastructure |
| Seismic                   | Seismic                   | $69              | $26     |             | SalesTech                                  | Software Applications   |
| Sierra                    | Sierra                    | $10,000          | $635    | 323         | AI applications (searchlagentslautomation) | Software Infrastructure |
| Snorkel                   | Snorkel Al                | $1,300           | $235    | 775         | Data governance & curation                 | Software Infrastructure |
| snyk                      | Snyk                      | $7,400           | $1,454  | 1,271       | Security & identity                        | Software Security       |
| stability.ai              | Stability Al              | $1,000           | $299    | 184         | Generative Al Creative Tools               | Software Infrastructure |
| stripe                    | Stripe                    | $91,500          |         | 8,550       | Payments                                   | FinTech                 |

|                   |                       | Valuation (SM)   | (SM)    |       |                                   |                         |
|-------------------|-----------------------|------------------|---------|-------|-----------------------------------|-------------------------|
| TECHNOLOGY        |                       |                  |         |       |                                   |                         |
|                   |                       | nla              | nla     | nla   | Al Video Animation                | Software Infrastructure |
|                   | Talkdesk              | $10,430          | $481    | 1,500 | Contact Center                    | Software Applications   |
| tenstorrent       | Tenstorrent           | $2,600           | $1,034  | 454   | Al Computel XPU Silicon           | Semiconductors          |
| THINKING MACHINES | Thinking Machine Labs | $12,000          | $2,010  | 83    | Data & Al platforms               | Software Infrastructure |
|                   | ThoughtSpot           | $4,424           | $809    | 886   | Augmented Analytics               | Software Infrastructure |
| together ai       | Together Al           | $3,300           |         | 246   | Al inference & compute platforms  | Software Infrastructure |
| tomorrow          | Tomorrow.io           | $409             | $333    | 214   | Al Weather Intelligence Platfrom  | Space- as-a-Service     |
| Trulioo           | Trulioo               | $1,750           | $491    | 406   | Identity Verification             | Software                |
| Typeface          | Typeface              | $1,000           | $166    | 186   | Creative Al & Design Tools        | Software Infrastructure |
| Vast              | VAST Data             |                  | $393    | 1,012 | Data infrastructure               | Software Infrastructure |
| VECTRA            | Vectra AI             | $1,120           | $361    | 655   | Intelligence/SIEM                 | Security Software       |
| Vercel            | Vercel                | $9,000           | $963    | 755   | DevOps & IT ops platforms         | Software Infrastructure |
| vsier             | Visier                | $1,000           | $220    | 600   | AI HR Analytics                   | Software                |
|                   | VRIFY                 | nla              | $24     | 107   | Al Mineral Exploration            | Software                |
| Woaviate          | Weaviate              | $200             | $68     | 129   | Vector Database                   | Software Infrastructure |
|                   | Windsurf              | $2,850           | $243    | 275   | Al engineering tools & frameworks | Software Infrastructure |
| WRITER            | Writer                | $1,900           | $326    | 500   | Gen Al Writing Assistant          | Internet                |
|                   | xAI                   | $45,000          | $17,162 | 3,324 | GenAl models & multimodal APIs    | Software Infrastructure |
| zapier            | Zapier                | $4,000           | $3      | 1,312 | Workflow automation/iPaaS         | Software Infrastructure |

| Company Logo                | Company Name                | Valuation (SM)   | (SM)   | Headcount   | Product Category                | Sector                           |
|-----------------------------|-----------------------------|------------------|--------|-------------|---------------------------------|----------------------------------|
| HEALTHCARE                  |                             |                  |        |             |                                 |                                  |
|                             | 3D Side                     | $13              | $7     | 34          | Healthcare Technology Systems   | MedTech                          |
|                             | Aidoc                       | $686             | $420   | 488         | Healthcare Technology Systems   | Digital & Tech-enabled Health    |
|                             | Aiforia                     | nla              | nla    | nla         | Commercial Services             | Diagnostics & Life Science Tools |
| Ambience                    | Ambience                    | $1,250           | $319   | 133         | Healthcare Technology Systems   | Digital & Tech-enabled Health    |
| ARMILLA                     | Armilla AI                  | nla              | $7     | 17          | Al Risk Mitigation              | Healthcare Technology Systems    |
| ASIMOV                      | Asimov                      | $1,225           | $205   | 70          | Al & Health Tech/Life Sciences  | Biotechnology                    |
|                             | Augmedics                   |                  | $149   | 128         | Healthcare Devices and Supplies | MedTech                          |
| BenchSci                    | BenchSci                    | nla              | $174   | 369         | Biomedical Research             | Biotechnology                    |
| Benevolent                  | Benevolent AI               | $1,942           | $550   | 342         | AI                              | Biotechnology                    |
| bluedot                     | BlueDot                     | nla              | $13    | 86          | Infectious Disease Risk         | Commercial Services              |
|                             | BPGbio                      | nla              | $480   | 61          | Life Sciences & Oncology        | Biotechnology                    |
| carra                       | Caira Surgical              | $40              | $15    | 9           | Healthcare Technology Systems   | MedTech                          |
| canary                      | Canary Medical              | $600             | $124   | 64          | Healthcare Technology Systems   | MedTech                          |
|                             | Cleerly                     | $630             | $410   | 235         | Healthcare Technology Systems   | MedTech                          |
|                             | CloudMedx                   | $17              | $15    | 24          | Al Data Predictive Analytics    | Digital & Tech-Enabled Health    |
| corti                       | Corti                       |                  | $103   | 141         | Medical Al Platform             | Digital & Tech-Enabled Health    |
|                             | Deep Genomics               | nla              | $241   | 100         | AI Drug Discovery               | Biotechnology                    |
| deepcell                    | Deepcell                    | $223             | $98    | 100         | Cellanalysis                    |                                  |
|                             |                             | 4185             | $37    | 130         | Medical Scribe                  | Digital & Tech-Enabled Health    |
| elucid                      | Elucid                      | $175             | $145   | 122         | Healthcare Technology Systems   | MedTech                          |
| eritel                      | Epitel                      | $30              | $13    | 48          | Diagnostics                     | Medical Technology               |
|                             | Evozyne                     | $310             | $135   | 57          | Synthetic protein generation    | Biotechnology                    |
| exai                        | Exai Bio                    |                  | $71    | 51          | Early cancer detection          | Diagnostics & Life Science Tools |
| FATHOM                      | Fathom                      | $2               | $16    | 5           | Software                        | Digital & Tech-enabled Health    |
| Formation 8io Formation Bio | Formation 8io Formation Bio | $1,700           | $619   | 178         | Al & Health Tech/Life Sciences  | Biotechnology                    |

| Company Logo   | Company Name           | Valuation (SM)   | (SM)   | Headcount   | Product Category                    | Sector                           |
|----------------|------------------------|------------------|--------|-------------|-------------------------------------|----------------------------------|
| HEALTHCARE     |                        |                  |        |             |                                     |                                  |
| Freenome;      | Freenome               | $2,200           | $1,352 | 416         | Healthcare Technology Systems       | Diagnostics & Life Science Tools |
|                | Genesis Therapeutics   | $424             | $327   | 135         | Molecular generation                | Biotechnology                    |
| GENOMENON'     | Genomenon              | $68              | $37    | 150         | Pharmaceuticals and Biotechnology   | Diagnostics & Life Science Tools |
|                | Hippocratic Al         | $1,640           | $278   | 190         | Healthcare Technology Systems       | Digital & Tech-enabled Health    |
| Imagene        | Imagene                |                  | $45    | 31          | Healthcare Technology Systems       | Diagnostics & Life Science Tools |
| immungi        | Immunai                | $1,100           | $295   | 186         | Al & Oncology                       | Biotechnology                    |
|                | Insitro                | $2,500           | $643   | 301         | AI & TMT                            | Biotechnology                    |
| Isomorphic     | Labs | Isomorphic Labs | $1,794           | $579   | 200         | Al & Life Sciences                  | Biotechnology                    |
|                | K Health               |                  | $441   | 405         | Digital Al Primary Care             | Digital & Tech-Enabled Health    |
| komodo         | Komodo Health          | $3,300           |        | 802         | Data analytics Al platform          | Digital & Tech-Enabled Health    |
|                | Lila Sciences          | $1,230           | $235   | 188         | Al & Big Data                       | Biotechnology                    |
|                | Luna Diabetes          | $46              | $24    | 8           | Healthcare Technology Systems       | MedTech                          |
|                | Nucleai                | $71              | $61    | 100         | Healthcare Technology Systems       | Diagnostics & Life Science Tools |
|                | OnPoint Surgical       | $120             | $61    | 40          | Healthcare Devices and Supplies     | MedTech                          |
|                | OpenEvidence           | $3,500           | $345   | 36          | Healthcare Technology Systems       | Digital & Tech-enabled Health    |
| OWKIN          | Owkin                  | $1,645           |        | 467         | Healthcare Technology Systems       | Diagnostics & Life Science Tools |
|                | Pando Bioscience       | nla              | $1     | 7           | Generative Al-driven drug discovery | Biotechnology                    |
| PathAl         | PathAl                 | $1,015           | $395   | 300         | Pharmaceuticals and Biotechnology   |                                  |
|                | Pathos                 | 600 $1,E         | $467   | 85          | Al & HealthTech & Oncology          | Biotechnology                    |
| PRISTINE       | Pristine Surgical      | nla              | $36    | 37          | Healthcare Devices and Supplies     | MedTech                          |
| PROSCIA        | Proscia                | $243             | $129   | 123         | Healthcare Technology Systems       | Diagnostics & Life Science Tools |
| Quibim         | Quibim                 |                  | $71    | 111         | Healthcare Technology Systems       | Diagnostics & Life Science Tools |
| RAPIDAI        | RapidAl                | $600             | $103   | 229         | Diagnostics                         | Medical Technology               |
|                | RefleXion              | $1,307           | $676   | 236         | Healthcare Devices and Supplies     | MedTech                          |
| RELAY'         | Relay Therapeutics     | $1,738           | $1,450 | 197         | Digital Health & Oncology           | Biotechnology                    |

Notes: This watch list is by no means all-inclusive. There are many more companies innovating with AI than we could feasibly include, both in software and in the broader market. To that end, our software team has selected roughly half of the companies in this watch list that are representative of novel use cases or stand to take market share, and we've complemented that list with more limited contributions from other participating research teams. Source: FactSet, Company Websites, Canaccord Genuity Research

|              |                     | Valuation (SM)   | (SM)   |     |                                     |                               |
|--------------|---------------------|------------------|--------|-----|-------------------------------------|-------------------------------|
| HEALTHCARE   |                     |                  |        |     |                                     |                               |
| restor3d     | Restor3d            | $280             | $293   | 246 | Healthcare Devices and Supplies     | MedTech                       |
|              | Suki AI             | $295             | $165   | 334 | Clinicial documentation             | Digital & Tech-Enabled Health |
| Synchron     | Synchron            | 4385             | $140   | 131 | Healthcare Devices and Supplies     | MedTech                       |
|              | Synthego            | $1,200           | $462   | 176 | AI & Life Sciences                  | Biotechnology                 |
| TERRAY       | Terray Therapeutics | 4352             | $226   | 122 | Generative Al-driven drug discovery | Biotechnology                 |
|              | Vent Creativity     | $20              | $1     | 12  | Healthcare Technology Systems       | MedTech                       |
| VitalConnect | VitalConnect        | $463             | $383   | 183 | Healthcare Devices and Supplies     | MedTech                       |
|              | Viz.ai              | $1,200           | $289   | 300 | Diagnostics                         | Medical Technology            |
|              | Xaria Therapeutics  | $2,700           | $1,000 | 134 | AI & Life Sciences                  | Biotechnology                 |

|                     |                     | Valuation (SM)   | (SM)           |                |                            |                |
|---------------------|---------------------|------------------|----------------|----------------|----------------------------|----------------|
| SUSTAINABILITY      | SUSTAINABILITY      | SUSTAINABILITY   | SUSTAINABILITY | SUSTAINABILITY | SUSTAINABILITY             | SUSTAINABILITY |
| agerpointAgerpoint_ | agerpointAgerpoint_ | $63              | $30            | 34             | Remote Sensing/ Analytics  | AgTech         |
| gy Agtonomy         | gy Agtonomy         | $239             |                | 46             | Autonomous Tractor         | AgTech         |
|                     |                     | $15,000          | $1,202         | 492            | Software                   | Sustainability |
| ARABLE              | Arable              | nla              | $3             | 8              | Remote Sensing/Analytics   | AgTech         |
|                     | Burro               | $74              | $45            | 67             | Autonomous Tractor         | AgTech         |
| CIBO                | CIBO Technologies   | $300             | $105           | 40             | Remote Sensing/ Analytics  | AgTech         |
|                     | Figure AI           | $39,000          | $2,345         | 120            | Computer Hardware          | Sustainability |
| Gatik               | Gatik               | $810             | $273           | 150            | Commercial Services        | Sustainability |
| MONARCH             | Monarch Tractor     | $518             | $252           | 233            | Autonomous Tractor         | AgTech         |
|                     | Nuro                | $6,000           | $2,332         | 974            | local goods transportation | Sustainability |
|                     | PlusAI              | $1,500           | $529           | 470            | Autonomous dr riving       | Sustainability |
|                     | Precision AI        | nla              | $20            | 32             | Remote Sensing/ Analytics  | AgTech         |
|                     | Stack AV            | nla              | $1,000         | 150            | Autonomous trucking        | Sustainability |
| TerraPower          | Terrapower          | $1,000           | $1,658         | 859            | Energy Equipment           | Sustainability |
|                     | Terrestrial Energy  | nla              | $170           | 75             | Energy Services            | Sustainability |
|                     | Torc Robotics       |                  | n/a            | 867            | Software                   | Sustainability |
| VERDANT ROBOTICS    | Verdant Robotics    | $126             | $58            | 45             | Precision Equipment        | AgTech         |
|                     | Waabi               | nla              |                | 200            | Software                   | Sustainability |
|                     | Waymo               | $45,000          | $11,100        | 3,317          | Transportation             | Sustainability |

|          |                      | Valuation (SM)   | (SM)   |       |                                         |                          |
|----------|----------------------|------------------|--------|-------|-----------------------------------------|--------------------------|
| CONSUMER |                      |                  |        |       |                                         |                          |
|          | Curology             | 4832             | $62    | 206   | AI/AR Driven Skin Care Products         | Beauty, Health, Wellness |
|          | Function of Beauty   | $1,100           | 4167   | 161   | AI/AR Driven Hair , Body, Skin Products | Beauty, Health, Wellness |
|          | Pepperfry            | $366             | $310   | 1,000 | Furniture and Home Dcor                | Home, Outdoor, and Auto  |
| Revieve  | Revieve              | $10              | $3     | 78    | AI/AR Solutions for Beauty /Retail      | Beauty, Health, Wellness |
|          | Vestiaire Collective | 41,001           | $714   | 751   | Second-hand Fashion                     | Home, Outdoor, and Auto  |

Individuals identified as 'Sector Coverage' cover a subject company's industry in the identified jurisdiction, but are not authoring analysts of the report.

Date and time of first dissemination: October 08, 2025, 06:23 ET Date and time of production: October 08, 2025, 06:23 ET

SPECULATIVE: The stock bears significantly above-average risk and volatility. Investments in the stock may result in material loss.

In line with Article 44(4)(b), MiFID II Delegated Regulation, we disclose price performance for the preceding five years or the whole period for which the financial instrument has been offered or investment service provided where less than five years. Please note price history refers to actual past performance, and that past performance is not a reliable indicator of future price and/or performance.

Canaccord Genuity research is posted on the Canaccord Genuity Research Portal and will be available simultaneously for access by all of Canaccord Genuity's customers who are entitled to receive the firm's research. In addition research may be distributed by the firm's sales and trading personnel via email, instant message or other electronic means. Customers entitled to receive research may also receive it via third party vendors. Until such time as research is made available to Canaccord Genuity's customers as described above, Authoring Analysts will not discuss the contents of their research with Sales and Trading or Investment Banking employees without prior compliance consent. For further information about the proprietary model(s) associated with the covered issuer(s) in this research report, clients should contact their local sales representative.

Research Analysts may, from time to time, discuss 'short-term trade ideas' in research reports. A short-term trade idea offers a near-term view on how a security may trade, based on market and trading events or catalysts, and the resulting trading opportunity that may be available. Any such trading strategies are distinct from and do not affect the analysts' fundamental equity rating for such stocks. A short-term trade idea may differ from the price targets and recommendations in our published research reports that

reflect the research analyst's views of the longer-term (i.e. one-year or greater) prospects of the subject company, as a result of the differing time horizons, methodologies and/or other factors. It is possible, for example, that a subject company's common equity that is considered a long-term 'Hold' or 'Sell' might present a short-term buying opportunity as a result of temporary selling pressure in the market or for other reasons described in the research report; conversely, a subject company's stock rated a long-term 'Buy' or 'Speculative Buy' could be considered susceptible to a downward price correction, or other factors may exist that lead the research analyst to suggest a sale over the short-term. Short-term trade ideas are not ratings, nor are they part of any ratings system, and the firm does not intend, and does not undertake any obligation, to maintain or update short-term trade ideas. Short-term trade ideas are not suitable for all investors and are not tailored to individual investor circumstances and objectives, and investors

should make their own independent decisions regarding any securities or strategies discussed herein. Please contact your salesperson for more information regarding Canaccord Genuity's research.

This research has been approved by Canaccord Genuity Corp., which accepts sole responsibility for this research and its dissemination in Canada. Canaccord Genuity Corp. is registered and regulated by the Canadian Investment Regulatory Organization (CIRO) and is a Member of the Canadian Investor Protection Fund. Canadian clients wishing to effect transactions in any designated investment discussed should do so through a qualified salesperson of Canaccord Genuity Corp. in their particular province or territory.

Canaccord Genuity LLC, a US registered broker-dealer, accepts responsibility for this research and its dissemination in the United States. This research is intended for distribution in the United States only to certain US institutional investors. US clients wishing to effect transactions in any designated investment discussed should do so through a qualified salesperson of Canaccord Genuity LLC. Analysts employed outside the US, as specifically indicated elsewhere in this report, are not registered as research analysts with FINRA. These analysts may not be associated persons of Canaccord Genuity LLC and therefore may not be subject to the FINRA Rule 2241 and NYSE Rule 472 restrictions on communications with a subject company, public appearances and trading securities held by a research analyst account.

This research is distributed in Australia by Canaccord Genuity (Australia) Limited ABN 19 075 071 466 holder of AFS Licence No 234666. To the extent that this research contains any advice, this is limited to general advice only. Recipients should take into account their own personal circumstances before making an investment decision. Clients wishing to effect any transactions in any financial products discussed in the research should do so through a qualified representative of Canaccord Genuity (Australia) Limited or its Wealth Management affiliated company, Canaccord Genuity Financial Limited ABN 69 008 896 311 holder of AFS Licence No 239052. This report should be read in conjunction with the Financial Services Guide available here - Financial Services Guide.

This research is distributed in Hong Kong by Canaccord Genuity (Hong Kong) Limited which is licensed by the Securities and Futures Commission. This research is only intended for persons who fall within the definition of professional investor as defined in the Securities and Futures Ordinance. It is not intended to be distributed or passed on, directly or indirectly, to any other class of persons. Recipients of this report can contact Canaccord Genuity (Hong Kong) Limited. (Contact Tel: +852 3919 2561) in respect of any matters arising from, or in connection with, this research.

None of the material, nor its content, nor any copy of it, may be altered in any way, reproduced, or distributed to any other party including by way of any form of social media, without the prior express written permission of the entities listed above.